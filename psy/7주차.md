# 7주차 - 5장 마무리, 6.2장까지

날짜: 2026년 2월 11일
완료: No

# 5.2 어떻게 캐시 친화적인 프로그램을 작성할까?

## 5.2.1 프로그램 지역성의 원칙

 지역성의 원칙은 프로그램이 매우 규칙적으로 메모리에 접근한다는 본질을 가지고 있다.

시간적 지역성이란 프로그램이 메모리 조각에 접근하고 나서 이 조각을 여러 번 참조하는 경우를 말한다.
캐시 친화성이 매우 높으며, 캐시에 데이터가 있다면 메모리에 접근하지 않아도 반복적으로 캐시의 적중이 가능하다.

공간적 지역성이란 프로그램이 메모리 조각에 접근하면 그 인접한 메모리도 같이 참조할 수 있는 경우를 말한다. 
캐시 친화적이며, 요청한 메모리의 인접 데이터도 함께 캐시에 저장되므로 인접 데이터에 접근할 때 캐시가 적중한다.

## 5.2.2 메모리 풀 사용

메모리를 동적으로 할당받을 때 malloc을 사용하는데, 할당 받으면 메모리 조각 N개가 힙 영역에 흩어져 있기 때문에 공간적 지역성이 좋지않다.

메모리풀은 커다란 메모리 조각을 미리 할당받기 때문에 캐시 친화적이다. 메모리 풀을 초기화할 때 연속적인 메모리 공간을 할당받으며, 우리가 사용할 데이터 또한 연속적인 메모리 공간 내에 존재하여 요청되기 때문에 데이터가 집중적으로 모여 있는 형태로 접근이 가능하다.

## 5.2.3 struct 구조체 재배치

연결 리스트의 구조체는 다음과 같다.

```c
#define SIZE 10000

struct List{
	List* next;
	int arr[SIZE];
	int value;
}
```

연결리스트의 탐색 프로그램은 다음과 같이 작성할 수 있다. 리스트를 순회하면서 값을 차례로 살펴보는 로직이다.

```c
bool find(struct List* list, int target){
	while (list){
		if(list->value == target){
			return true;
		}
		list = list → next;
	}
	return false;
}
```

빈번하게 사용되는 항목은 next, value이며, arr은 전혀 사용되지 않는다. 연속적인 주소공간에 arr이 next와 value 사이에 있기 때문에 공간적 지역성이 나빠진다. 따라서 더 좋은 방법은 next 포인터와 value 값을 함께 배치하는 것이다.

```c
#define SIZE 10000

struct List{
	List* next;
	int value;
	int arr[SIZE];
}
```

위와 같이 수정하면 next와 value가 서로 인접해 있기 때문에 캐시에 next가 있다면 value도 포함되어 있을 수 있다. 이를 통해 공간적 지역성 원리로 구조체 형태를 최적화할 수 있다.

## 5.2.4 핫 데이터와 콜드 데이터의 분리

캐시 용량이 제한적인데 연결 리스트에는 보통 노드가 여러개 있으며 캐시해야 하는 노드도 많아진다. 그래서 연결 리스트 자체가 차지하는 저장 공간이 커지면 캐시에 저장할 수 있는 노드도 줄어든다. 따라서 arr을 그대로 구조체에 넣지 않고 arr의 포인터를 저장하면 더욱 최적화시킬 수 있다.

```c
#define SIZE 10000

struct List{
	List* next;
	int value;
	struct Arr* arr;
}

struct Arr{
	int arr[SIZE];
}
```

next와 value 처럼 빈번하게 접근하는 값을 핫 데이터라고 하고, arr처럼 거의 접근하지 않는 데이터를 콜드 데이터라고 한다.

## 5.2.5 캐시 친화적인 데이터 구조

`std:vector` 컨테이너는 배열로써 하나의 연속된 메모리 공간에 할당되고, `std:list`는 여기저기 흩어져서 저장되기 때문에 공간적 지역성 관점에서 `std:vector`를 사용하는 것이 더 캐시 친화적이다.

그러나 상황에 따라 노드가 빈번하게 추가되고 삭제될 때는 연결리스트를 사용하는 것이 더 낫다. 만약, 연결리스트 노드의 추가 삭제라는 장점을 유지하면서 캐시 친화적이어야 한다면, 연결 리스트를 생성할 때 직접 정의한 메모리풀에서 메모리를 요청하면 된다.

이러한 최적화를 할 때는 반드시 일종의 분석 도구를 사용하여 캐시의 적중률이 시스템 성능의 병목이 되는지를 판단해야 한다.

## 5.2.6 다차원 배열 순회

### 행 우선 방식

A4*8 배열을 행과 열 순서로 순회하면서 값을 모두 더하는 과정을 행 우선 방식으로 캐시와 메모리의 관점에서 살펴보자.

1. 캐시가 비어있기 때문에 적중할 수 없다. A[0][0] 메모리에 접근하고 A[0][3]이 캐시에 저장된다.
2. A[0][3]까지는 캐시가 적중하기 때문에 메모리에 접근하지 않는다.
3. 캐시에 A[0][4]가 없기 때문에 메모리에 접근한다. A[0][4]를 포함해 A[0][7]이 캐시에 저장된다.
4. A[0][7]까지는 캐시가 적중하기 때문에 메모리에 접근하지 않는다.
5. 배열의 두 번째 행부터는 첫 번째 행에 대한 접근 패턴과 완전히 동일하다.

```
~~[0][0]~~ [0][1] [0][2] [0][3] ~~[0][4]~~ [0][5] [0][6] [0][7]
...
```

전체 데이터 32개 중, 8개가 캐시에 적중하지 못하므로 적중률은 75%에 해당한다.

### 열 우선 방식

위와 같은 상황을 열 우선 방식으로 살펴보자.

1. 캐시가 비어있기 때문에 적중할 수 없다. A[0][0] 메모리에 접근하고 A[0][3]이 캐시에 저장된다.
2. 캐시에 A[0][8]가 없기 때문에 메모리에 접근한다. A[0][8]을 포함해 A[0][11]이 캐시에 저장된다.
3. 이와 같이 캐시는 매번 적중에 실패하며 캐시 적중률은 0이 된다.

---

# 5.3 다중 스레드 성능 방해자

## 5.3.1 캐시와 메모리 상호 작용의 기본 단위: 캐시 라인

다중 스레드 프로그래밍은 다중 코어 리소스를 최대한 활용할 수 있지만 캐시가 포함되면서 새로운 문제가 발생한다.

프로그램이 데이터에 접근했을 때 캐시에 저장되는 묶음 데이터를 캐시 라인이라고 한다.

## 5.3.2 첫 번째 성능 방해자: 캐시 튕김 문제

2개의 스레드가 병렬로 전역 변수 a를 1씩 5억번 증가시키는 코드와

```c
atomic<int> a;

void thr(){
	for (int i=0;i<500000000; i++){
		++a;
	}
}

void run(){
	thread t1=thread(thr);
	thread t2=thread(thr);
	
	t1.join();
	t2.join();
}
```

단일 스레드로 전역 변수 a를 10억번 증가시키는 코드가 있다.

```c
atomic <int> a;

void run(){
	for(int i=0; i<1000000000; i++){
		++a;
	}
}
```

두 코드의 실행 결과는 각각 16초, 8초로 단일 스레드였을 때가 더 빠르다.

perf stat 명령어로 프로그램의 통계 정보를 봤을 때 insn per cycle이라는 하나의 클럭 주기에 cpu가 실행하는 프로그램에서 기계 명령어를 몇 개 실행하는지를 알려주는 항목이 있다.

다중 스레드 프로그램의 경우는 0.15로 하나의 클럭 주기 동안 기계 명령어가 0.15개 실행됐음을 알 수 있다. 단일 스레드 프로그램의 경우 0.6으로 다중 스레드의 4배에 달한다.

여기서 단일 스레드 프로그램에서 전역 변수 a를 일반 int형으로 했을 때 실행 시간이 더 빨라져서 2초만에 완료된다. 이 때, insn per cycle은 1.03이 된다. 즉, 클럭 주기 한 번에 기계 명령어를 하나 이상 실행할 수 있다.

다중 스레드 프로그램의 성능이 좋지 않은 이유는 캐시 일관성 때문이다. 캐시 일관성을 보장하기 위해 두 코어의 캐시에 동일한 전역 변수 a가 각각 저장된다. 

두 스레드에 있는 캐시를 각각 c1, c2라고 하자. c1의 변수가 1 증가되면 c2에서 a 변수를 무효화 해야하므로 캐시튕김이 발생한다. 때문에 c2는 메모리에 접근해서 a 값을 읽어야 한다. 마찬가지로 c2의 변수가 1 증가되면 c2에서 a 변수를 무효화 해야하므로 캐시 튕김이 발생하고, c2은 메모리에 접근해서 a 값을 읽는다.
이처럼 c1, c2 캐시가 서로 상대 캐시를 무효화하면서 튕겨내면서 성능을 저하시킨다.

## 5.3.3 두 번째 성능 방해자: 거짓 공유 문제

다음과 같은 구조체에서 값을 증가시킨다고 하자.

```c
struct data{
	int a;
	int b;
};

struct data global_data;
```

다중 스레드로 병렬적으로 하는 코드와

```c
void add_a(){
	for(int i=0; i<500000000; i++){
		++ global_data.a;
	}
}

void add_b(){
	for(int i=0; i<500000000; i++){
		++ global_data.b;
	}
}

void run(){
	thread t1 = thread(add_a);
	thread t2 = thread(add_b);
	
	t1.join();
	t2.join();
}
```

단일 스레드로 하는 코드가 있다.

```c
void run(){
	for(int i=0; i<500000000; i++){
		++global_data.a;
	}
	
	for(int i=0; i<500000000; i++){
		++global_data.b;
	}
}
```

다중 스레드의 경우 실행 시간은 3초, 단일 스레드는 2초로 단일 스레드의 경우가 더 빨랐다.

단일 스레드의 경우 어떤 변수도 공유하지 않으며, 다중 코어를 충분히 활용하지 않음에도 더 빠른 이유는 global_data의 두 변수가 같은 하나의 캐시라인을 공유하고 있어, a 변수가 캐시에 적중할 경우 b 변수도 같이 저장되기 때문이다. 이를 거짓 공유하고 한다.  따라서 위와 같이 캐시 튕김 문제가 발생하게 된다.

두 변수 a와 b 사이에 사용하지 않는 변수를 채우면 서로 같은 캐시라인을 공유하지 않게 되어 쉽게 문제를 해결할 수 있다.

---

# 5.4 봉화희제후와 메모리 장벽

## 5.4.1 명령어의 비순차적 실행: 컴파일러와 OoOE

cpu는 프로그래머가 작성한 대로 기계 명령어를 실행하지 않는다. 명령어 실행은 다음과 같이 두 단계를 거친다.

1. 기계 명령어를 생성하는 단계: 컴파일 중에 명령어를 재정렬한다.
2. cpu가 명령어를 실행하는 단계: 실행 중에 명령어가 비순차적으로 실행된다.

일반적으로 우리는 다음과 같이 cpu가 작업한다고 생각한다.

1. 기계 명령어를 가져온다
2. 명령어의 피연산자가 레지스터에 저장되는 등 이미 준비 완료된 상태라면 명령어는 실행 단계에 들어간다. 준비가 되지 않았다면 대기한다.
3. 데이터가 이미 준비되었다면 명령어를 실행한다.
4. 실행 결과를 다시 기록한다.

그러나 피연산자가 아직 준비되지 않은 경우 cpu는 반드시 대기해야 하기 때문에 비효율적이다. 이를 다음과 같이 개선할 수 있다.

1. 기계 명령어를 가져온다.
2. 명령어를 대기열에 넣고 명령어에 필요한 피연산자를 읽는다.
3. 명령어는 대기열에서 피연산자의 준비가 완료될 때까지 대기한다. 이미 준비 완료된 명령어가 먼저 실행 단계에 들어올 수 있다.
4. 기계 명령어를 실행하면 실행 결과를 대기열에 넣는다.
5. 명령어의 원래 실행 순서에 따라 유효한 결과를 얻기 위해 이전 명령어의 실행 결과가 기록될 때까지 기다렸다가 현재 명령어의 실행 결과를 기록한다.

이를 비순차적 명령어 처리(OoOE)라고 한다. cpu와 메모리의 속도 차이가 많이 나기 때문에 기계 명령어를 엄격한 순서대로 실행하면 파이프라인 내부에 빈공간 슬록이 생긴다. 이를 이미 준비 완료된 다른 명령어로 빈 공간을 메꾸는 식으로 효율성을 높인 것이다.

## 5.4.2 캐시도 고려해야 한다

캐시를 갱신하고 일관성을 유지시킬 방법이 필요하다. 이 과정은 시간과 리소스를 많이 소모하기 때문에 저장버퍼 등을 대기열에 추가하여 최적화 한다. 쓰기 작업이 대기열에 직접 기록하기 때문에 캐시는 즉시 갱신되지 않고 cpu는 캐시가 갱신되기를 기다리지 않고 다음 명령어를 계속 실행할 수 있다.

쓰기 작업은 비동기 과정이기 때문에 캐시와 메모리를 갱신할 때까지 기다리지 않고 그 다음 명령어를 실행할 수 있다. 아래의 예시를 살펴보자.

```c
// a의 초깃값은 0, y의 초깃값은 100이라고 가정한다.
a=1;
b=y;
```

a=1;을 실행할 때 저장버퍼에 있기 때문에 캐시a의 갱신까지 기다리지 않고 b=y;를 실행할 수 있다. 이 때, b는 100이 된다. b=y가 먼저 실행됐기 때문에 캐시 b가 b=100을 인지한 시점에서 a는 아직 0일 수 있다. 이와 같이 최종적으로는 마치 2번째가 먼저 실행되고 이어서 1번째가 실행된 것처럼 보일 수 있다.

그러나 해당 스레드 내부에서는 비순차적 실행을 볼 수 없다. 다음을 실행했을 때 0이 아닌 1을 출력한다는 점에서 알 수 있다.

```c
a=1;
b=2;

print(a);
```

이는 cpu 설계가 이를 보장하기 때문이다. 즉, 비순차적 실행은 자기 이외의 다른 코어가 해당 코어를 바라볼 때만 목격되는 현상이다.

명령어 비순차적 실행은 성능 향상을 위한 것이며 cpu는 비순차적으로 실행하더라도 순차적으로 실행했을 때의 결과값을 반환하도록 보장하므로서 최적화를 이루어낼 수 있다.

## 5.4.3 네 가지 메모리 장벽 유형

### LoadLoad

간단한 메모리 읽기 명령어조차도 일부 cpu에서는 더 높은 성능을 위해 비순차적으로 실행된다. loadload는 cpu가 Load 명령어를 실행할 때 다음 Load 명령어가 비순차적 실행으로 먼저 실행되는 것을 방지한다.

### StoreStore

cpu가 store 명령어를 실행할 때 다음 store 명령어가 비순차적 실행으로 먼저 실행되는 것을 방지한다.

기본 설정 상황에서 변수 값이 실제로 언제 메모리에 갱신되는지 알 수 없지만 storestore 장벽을 추가하면 다른 코어에서 변수의 갱신 순서와 코드 순서가 일치하게 된다.

### LoadStore

쓰기 작업은 상대적으로 오래 걸리므로 일반적으로 읽기 작업이 먼저 실행된다. 이 때, 읽기 작업보다 쓰기 작업을 우선적으로 실행하도록 보장하는 것이 LoadStore이다.

### StoreLoad

쓰기 명령어보다 비순차적 실행으로 읽기 명령어를 먼저 실행하는 것을 방지한다. cpu가 해당 쓰기 명령어에 필요한 작업이 얼마나 복잡하든, 대기하는 시간이 얼마나 길든 이 유휴 시간 동안 다음에 오는 읽기 작업을 미리 실행하지 않으며, storeload 메모리 장벽 이전에 변수를 다른 코어가 해당 장벽 이후에 읽으면 그 값이 반드시 최신 값이라는 것을 보장할 수 있다.

## 5.4.4 획득-해제 의미론

획득 의미론은 메모리 읽기 작업에 대한 것이다. 예를 들어 load 뒤에 있는 모든 메모리 작업은 이 load 작업 이전에는 실행 불가능하다.

해제 의미론은 메모리 쓰기 작업에 대한 것이다. 예를 들어 store 앞에 있는 모든 메모리 작업은 이 store 작업 이후에는 실행 불가능하다.

## 5.4.5 C++에서 제공하는 인터페이스

서로 다른 유형의 cpu는 서로 특징이 있기 때문에 특정 유형의 cpu만 대상으로 코드를 작성하면 다른 플랫폼에 이식할 방법이 없다. 그래서 이식성이 높은 잠금 없는 프로그래밍을 하려면 언어 수준에서 제공하는 획득-해제 의미론을 사용해야만 한다.

C++11의 atomic 원자 라이브러리에서 제공하는 코드는 다음과 같다.

```c
#include <atomic>

std::atomic_thread_fence(std::memory_order_acuire);
std::atomic_thread_fence(std::memory_order_release);
```

이를 사용하면 거의 모든 유형의 cpu에서 정확하게 동작한다.

## 5.4.7 누가 명령어 재정렬에 관심을 가져야 하는가: 잠금 없는 프로그래밍

재졍렬 문제는 공유 변수가 잠금 보호 없이 여러 스레드에서 사용될 때 발생한다. 따라서 잠금 없는 프로그래밍을 해야 할 때만 신경 쓰면 된다.

잠금을 유지하는 스레드가 os에 의해 일시중지된 후 잠금이 필요한 모든 다른 스레드는 앞으로 나아갈 수 없다. 예시 상황은 다음과 같다.

1. 스레드a가 lock을 잡음
2. 그런데 os가 A를 스케줄링에서 멈춰버림
3. 스레드b,c,d는 lock이 필요함
4. 하지만 a가 lock을 잡고 있으니까 전부 대기

잠금 없는 프로그래밍은 운영체제가 어떻게 순서 스케줄링을 하든 어떤 스레드가 멈추더라도, 최소한 하나의 스레드는 반드시 작업을 완료할 수 있다. 이를 lock-free라고 한다.

잠금을 사용하여 프로그래밍을 할 때 잠금이 명령어 다음과 같은 재정렬 문제를 자동으로 처리한다.

- 상호 배제
- 메모리 가시성 보장

잠금은 모든 메모리 작업이 반드시 임계영역 내에서 실행되기를 기다려야 한다. 즉 lock을 획득하면 이전에 실행 중이던 메모리 작업이 다 끝나야 하고 lock을 해제하면 변경된 값이 다른 스레드에게 보이도록 flush된다.

## 5.4.8 잠금 프로그래밍과 잠금 없는 프로그래밍

상호배제는 공유 리소스를 보호하는데 사용된다. 동시에 최대 스레드 하나만 상호배제를 보유할 수 있으며, lock이 사용되면 해당 lock을 요청하는 다른 스레드는 운영체제에 의해 대기 상태로 진입한다. 이는 lock을 사용한 스레드가 lock을 해제할 때까지 계속된다.

lock을 요청하는 스레드는 계속 lock이 해제되었는지 여부를 반복적으로 확인한다. 이 때, os에 의해 대기상태로 진입하지 않고 이를 spinlock이라고 한다.

잠금 없는 프로그래밍은 어떤 스레드가 공유 자원을 사용하고 있을 때 다른 스레드도 해당 공유 자원을 요청한다면 일단 다른 필요한 작업으로 넘어간다. 이처럼 성능 향상보다는 스레드가 항상 대기 없이 어떤 일을 하고있는 것에 중점을 두고있다. 때문에 코드 구현이 매우 어려우며 리소스 경젱 문제가 있지만 매우 간단한 특정 상황에서는 적은 수의 원자적 작업으로 구현이 가능하며 더 성능이 나을 수 있다.

## 5.4.9 명령어 재정렬에 대한 논쟁

cpu의 명령어 재정렬 문제를 하드웨어에서 처리할지 소프트웨어로 처리할지에 대해서 끊임없이 고민하고 있다.

복잡한 내용을 떠나, 중요한 내용을 정리하면 다음과 같다.

1. 성능을 위해 cpu는 반드시 프로그래머가 코드를 작성한 순서대로 엄격하게 기계 명령어를 실행할 필요가 없다.
2. 프로그램이 단일 스레드인 경우 프로그래머는 명령어의 비순차적 실행을 볼 수 없으므로, 단일 스레드 프로그램은 명령어 재정렬에 신경 쓸 필요가 없다.
3. 메모리 장벽의 목적은 특정 코어가 명령어를 실행하는 순서와 다른 코어에서 보이는 순서가 코드 순서와 일치하도록 만드는 것이다.
4. 멀티 스레드 잠금 없는 프로그래밍을 사용할 필요가 없다면 명령어 재정렬을 신경쓰지 않아도 된다.