# 4.6 CPU 진화론(상): 복잡 명령어 집합의 탄생

## 4.6.1 프로그래머의 눈에 보이는 CPU

모든 프로그램은 간단한 `helloworld`부터 대규모 응용 프로그램까지 결국 컴파일러를 거쳐 기계 명령어로 변환된다. CPU 관점에서는 프로그램의 크기나 복잡도와 무관하게 **기계 명령어의 나열**일 뿐이다.

프로그램은 실행 파일로 저장되며 실행 시 메모리에 적재된다. 이때, CPU는 메모리에서 명령어를 하나씩 읽어 실행하는 단순한 역할을 수행한다. 따라서 프로그래머의 관점에서 CPU는 매우 단순한 존재로 보이게 된다.

---

## 4.6.2 CPU의 능력 범위: 명령어 집합

CPU가 무엇을 할 수 있는지는 그 CPU가 어떤 **명령어 집합(Instruction Set Architecture, ISA)**을 가지고 있는지에 의해 결정된다. 명령어 집합이란 CPU가 이해하고 실행할 수 있는 모든 명령어의 목록이다.

사람의 능력을 이력서로 설명하듯, CPU의 능력 역시 명령어 집합을 통해 설명할 수 있다. 예를 들어 덧셈이 가능한지, 메모리에서 레지스터로 데이터를 옮길 수 있는지, 조건에 따라 분기할 수 있는지 등이 모두 명령어 집합에 포함된다.

즉, 명령어 집합은 **CPU가 할 수 있는 일의 범위를 정의하는 기준**이다. 프로그램은 이 명령어 집합 안에서만 동작할 수 있으며, CPU 설계 역시 이 명령어 집합을 중심으로 이루어진다.

---

## 4.6.3 추상화: 적을수록 좋다

1970년대까지 컴파일러 기술은 충분히 성숙하지 못했다. 이로 인해 많은 프로그램이 고급 언어가 아닌 **어셈블리어로 직접 작성**되었다.

당시 프로그래머들은 CPU 내부 동작을 직접 제어할 수 있는 방식을 선호했다. 추상화 계층이 많아질수록 성능 저하나 예측 불가능한 동작이 발생할 수 있다고 여겼기 때문이다.

이러한 배경에서 **추상화는 적을수록 좋다**는 인식이 강했다. 고급 언어보다 CPU에 가까운 형태의 코드가 더 효율적이라고 생각되었고, 이는 복잡 명령어 집합이 등장하는 중요한 배경이 된다.

---

## 4.6.4 코드도 저장 공간을 차지한다

<img width="510" height="295" alt="image" src="https://github.com/user-attachments/assets/ff6c1e0f-e84c-47b1-b0a2-e78a0a5845cb" />


현대 컴퓨터는 기본적으로 **폰 노이만 구조(Von Neumann Architecture)**를 따른다. 이 구조에서는 프로그램과 데이터가 동일한 메모리 공간에 저장된다.

프로그램은 디스크에 실행 파일 형태로 저장되며, 실행 시 메모리에 적재된다. 즉, 코드 역시 데이터와 마찬가지로 **저장 공간을 차지하는 대상**이다.

1970년대의 메모리 용량은 수 KB 수준으로 매우 제한적이었다. 이 작은 메모리에 더 많은 프로그램을 올리기 위해서는 코드 크기를 줄이는 것이 필수적이었다.

이로 인해 명령어를 최대한 압축하고, **하나의 명령어로 더 많은 작업을 수행하려는 설계**가 중요해졌다.

---

## 4.6.5 필연적인 복잡 명령어 집합의 탄생

프로그래머가 더 적은 코드로 더 많은 작업을 수행해야 했던 환경에서, 복잡 명령어 집합은 필연적인 선택이었다.

복잡 명령어 집합(CISC)은 하나의 명령어가 여러 단계를 수행하도록 설계되었다. 이를 통해 코드 길이를 줄이고, 메모리 사용량을 최소화할 수 있었다.

당시 CPU는 명령어 인출(IF), 해독(ID), 실행(EX) 단계를 **하드웨어 회로로 직접 제어(hardwired)**하는 구조였다. 이 방식은 단순한 명령어에서는 효율적이지만, 명령어가 복잡해질수록 설계 난이도가 급격히 상승한다.

특히 명령어 길이가 가변적인 경우, CPU 내부 구조는 더욱 복잡해진다. 새로운 명령어를 추가할 때마다 하드웨어 수정이 필요했고, 이는 개발과 디버깅을 어렵게 만들었다.

---

## 4.6.6 마이크로코드 설계의 문제점

이러한 문제를 해결하기 위해 등장한 개념이 **마이크로코드(microcode)**이다. 마이크로코드는 복잡한 기계 명령어를 CPU 내부에서 여러 개의 간단한 내부 명령어로 분해하여 실행한다.

이를 통해 하드웨어 설계를 단순화하고, 명령어 확장에 대한 유연성을 확보할 수 있었다. 복잡한 동작을 소프트웨어처럼 CPU 내부에 저장해 처리하는 방식이다.

그러나 마이크로코드 역시 완전한 해결책은 아니었다. 마이크로코드에도 버그가 발생할 수 있으며, 이를 수정하는 것은 일반 소프트웨어보다 훨씬 어렵다. 또한 마이크로코드는 많은 트랜지스터를 소모한다. 실제로 Motorola 68000 프로세서에서는 전체 트랜지스터의 약 1/3이 마이크로코드 구현에 사용되었다.

데이비드 패터슨은 이러한 문제를 지적하며, **마이크로코드 자체가 또 다른 복잡성의 원인**이라고 주장했다. 이 문제의식은 이후 축소 명령어 집합으로 이어지게 된다.

---

# 4.7 CPU 진화론(중): 축소 명령어 집합의 탄생

## 4.7.1 복잡함을 단순함으로

복잡 명령어 집합이 등장한 이후, 기술 환경은 점차 변화하기 시작했다. 가장 큰 변화는 **메모리 가격의 급격한 하락**이다. 1970년대에는 수 KB 메모리가 매우 비싼 자원이었지만, 시간이 지나면서 메모리 용량은 커지고 가격은 빠르게 낮아졌다.

이로 인해 코드 크기를 극단적으로 줄여야 할 필요성이 점차 줄어들었다. 동시에 컴파일러 기술도 꾸준히 발전하여, 사람이 직접 어셈블리어를 작성하지 않아도 고급 언어를 효율적인 기계 명령어로 변환할 수 있게 되었다.

이러한 변화 속에서 기존의 복잡 명령어 집합에 대한 근본적인 질문이 제기되었다. **정말로 복잡한 명령어가 성능 향상에 도움이 되는가**라는 의문이다.

---

## 4.7.2 축소 명령어 집합의 철학

## 4.7.2 축소 명령어 집합의 철학

복잡 명령어 집합에 대한 반성을 바탕으로 **축소 명령어 집합(Reduced Instruction Set Computer, RISC)**의 철학이 등장했다. 이는 단순히 명령어의 개수를 줄이자는 발상이 아니라, **CPU 설계 전반을 단순화하자는 철학**이다.

이 철학은 주로 세 가지 측면에서 구체화되었다.

---

### 1) 명령어 자체의 복잡성

축소 명령어 집합의 첫 번째 특징은 **복잡한 명령어를 제거하고, 간단한 명령어 여러 개로 대체**하는 것이다. 하나의 명령어가 많은 일을 수행하도록 만들기보다는, 하나의 명령어가 수행하는 일을 최소화한다.

여기서 중요한 점은 “명령어 집합을 줄인다”는 말이 **명령어의 개수가 줄어든다는 의미가 아니라**는 것이다. 이는 하나의 명령어가 포함하는 연산의 복잡도가 줄어든다는 의미이다.

복잡 명령어 집합의 명령어가 하나의 작업 전체를 처리한다면, 축소 명령어 집합의 명령어는 그 작업을 구성하는 여러 작은 단계 중 하나만 수행한다. 예를 들어, 복잡 명령어 집합이 “먹는다”라는 행위를 한 번에 처리한다면, 축소 명령어 집합은 “이로 한 입 베어 문다”라는 단계를 수행하는 것에 가깝다.

이러한 설계를 통해 CPU 내부 구조는 단순해지고, 명령어 해석과 실행 과정도 예측 가능해진다.

---

### 2) 컴파일러 중심 설계

축소 명령어 집합의 두 번째 특징은 **컴파일러의 역할이 매우 중요해진다는 점**이다.

복잡 명령어 집합에서는 CPU 내부의 마이크로코드가 명령어 실행의 세부 사항을 담당한다. 이로 인해 컴파일러는 CPU 내부 동작을 알 수 없고, 최적화에도 한계가 있다.

반면 축소 명령어 집합에서는 CPU가 제공하는 명령어가 단순하고 명확하기 때문에, 더 많은 제어권이 컴파일러로 넘어간다. 컴파일러는 어떤 명령어를 어떤 순서로 배치할지, 어떻게 파이프라인을 효율적으로 채울지를 직접 고려할 수 있다.

이러한 철학은 **“흥미로운 작업은 컴파일러에게 맡긴다(Relegate Interesting Stuff to Compiler)”**라는 표현으로 요약되기도 한다. CPU는 단순한 실행 장치로 남고, 지능적인 최적화는 컴파일러가 담당한다.

---

### 3) LOAD/STORE 구조

축소 명령어 집합의 세 번째이자 가장 핵심적인 특징은 **LOAD/STORE 구조**이다.

축소 명령어 집합에서는 메모리에 직접 접근할 수 있는 명령어가 오직 LOAD와 STORE로 제한된다. 다른 모든 명령어는 CPU 내부의 레지스터만을 대상으로 연산을 수행한다.

즉, 산술 연산이나 논리 연산 명령어는 메모리의 데이터를 직접 처리할 수 없으며, 반드시 레지스터에 적재된 데이터만 다룰 수 있다. 메모리 접근과 연산을 명확히 분리한 구조이다.

이 설계는 복잡 명령어 집합과의 매우 분명한 차이점이다. 복잡 명령어 집합에서는 하나의 명령어가 메모리 접근과 연산, 결과 저장까지 모두 수행할 수 있지만, 축소 명령어 집합에서는 이러한 방식이 허용되지 않는다.

LOAD/STORE 구조를 채택함으로써 명령어 실행 단계가 단순해지고, 파이프라인 설계가 쉬워지며, 전체 CPU 성능 향상으로 이어진다.

---

## 4.7.3 복잡 명령어 집합과 축소 명령어 집합의 차이

축소 명령어 집합과 복잡 명령어 집합의 차이는 계산을 어떻게 수행하느냐에서 분명하게 드러난다. 예를 들어 메모리 주소 A와 B에 저장된 두 값을 곱한 뒤, 그 결과를 다시 메모리에 저장하는 상황을 가정한다.

복잡 명령어 집합에서는 가능한 한 **적은 수의 기계 명령어로 많은 작업을 수행**하는 것이 목표이다. 따라서 CPU에는 `MULT A, B`와 같은 명령어가 존재할 수 있다. 이 하나의 명령어에는 메모리에서 값 읽기, 두 값의 곱셈, 결과를 다시 메모리에 저장하는 과정이 모두 포함된다.

즉, 여러 단계의 작업이 하나의 기계 명령어 안에 묶여 있으며, 이는 고급 언어의 연산과 매우 유사한 형태이다. 이러한 설계는 코드 길이를 줄이고 저장 공간을 절약하는 데 유리하다.

반면 축소 명령어 집합에서는 하나의 명령어가 수행하는 일이 매우 제한적이다. 동일한 작업을 수행하기 위해서는 여러 개의 단순한 명령어를 순차적으로 실행해야 한다. 메모리에서 데이터를 읽는 명령어, 레지스터 간 곱셈을 수행하는 명령어, 결과를 다시 메모리에 저장하는 명령어가 각각 분리되어 존재한다.

이 방식은 명령어 수는 늘어나지만, 각 명령어의 동작이 명확하고 단순해진다는 특징을 가진다.

---

## 4.7.4 명령어 파이프라인

<img width="295" height="171" alt="image" src="https://github.com/user-attachments/assets/b3b3ada2-62a0-4380-92f5-375021836c5f" />


축소 명령어 집합에서 중요한 개념 중 하나는 **명령어 파이프라인**이다. 축소 명령어 집합의 명령어들은 구조가 단순하고 실행 시간이 거의 일정하다.

이로 인해 CPU는 명령어를 순차적으로 처리하는 대신, 여러 명령어를 겹쳐서 처리할 수 있다. 이를 파이프라인이라 한다. 한 명령어가 실행 단계에 있을 때, 다음 명령어는 해독 단계에, 그 다음 명령어는 인출 단계에 위치하는 식이다.

중요한 점은 각 명령어가 거의 동일한 실행 시간을 가지기 때문에, 파이프라인을 효율적으로 채울 수 있다는 것이다. 이는 CPU의 처리량을 크게 향상시킨다.

복잡 명령어 집합에서는 명령어마다 실행 시간이 크게 다르기 때문에 파이프라인을 안정적으로 구성하기 어렵다. 어떤 명령어는 매우 짧게 끝나고, 어떤 명령어는 여러 사이클을 소모하기 때문이다.

반면 축소 명령어 집합은 명령어 실행 시간을 균등하게 설계함으로써 파이프라인 구조에 매우 적합한 형태를 가진다.

---

## 4.7.5 천하에 명성을 떨치다

1980년대 중반 이후, 축소 명령어 집합을 기반으로 한 CPU들이 실제 성능에서 두각을 나타내기 시작했다. 이 시기에는 메모리 가격 하락과 컴파일러 기술 발전이 동시에 이루어지고 있었다.

그 결과, 축소 명령어 집합 CPU는 더 적은 트랜지스터로 더 높은 클럭 주파수를 달성할 수 있었고, 파이프라인을 적극적으로 활용해 높은 성능을 보였다.

대표적인 예로, MIPS R2000 프로세서는 당시 복잡 명령어 집합 기반의 x86 프로세서보다 우수한 성능을 보여주었다. 이로 인해 많은 CPU 제조업체들이 축소 명령어 집합 설계를 적극적으로 채택하기 시작했다.

이 시점에서 복잡 명령어 집합은 점차 설 자리를 잃는 것처럼 보였다. 심지어 일부에서는 x86과 같은 복잡 명령어 집합 구조가 곧 사라질 것이라는 예측도 등장했다.

그러나 실제 역사는 그렇게 단순하게 흘러가지 않았다. 복잡 명령어 집합은 이후 새로운 방식으로 진화하며 다시 반격에 나서게 된다.

---

# 4.8 CPU 진화론(하): 절체절명의 위기에서 반격

복잡 명령어 집합은 축소 명령어 집합의 등장으로 존폐의 위기에 놓였다. 축소 명령어 집합은 파이프라인에 최적화된 구조와 높은 클럭 주파수를 바탕으로 실제 성능에서 우위를 점하기 시작했다.

이 시점에서 복잡 명령어 집합 진영은 중요한 선택의 기로에 서게 된다. 기존 구조를 버리고 축소 명령어 집합으로 전환할 것인지, 아니면 기존의 강점을 유지한 채 새로운 방식으로 대응할 것인지에 대한 문제이다.

---

## 4.8.1 이길 수 없다면 함께하라: RISC와 동일한 CISC

복잡 명령어 집합 진영의 선택은 **축소 명령어 집합을 내부적으로 받아들이는 것**이었다. 즉, 겉으로는 복잡 명령어 집합을 유지하되, CPU 내부에서는 축소 명령어 집합과 유사한 방식으로 명령어를 실행하는 전략이다.

이를 위해 복잡 명령어 집합의 기계 명령어를 CPU 내부에서 더 단순한 명령어로 변환한다. 이 내부 명령어를 **마이크로 명령어(micro-operation)**라고 한다.

마이크로 명령어는 축소 명령어 집합의 명령어와 마찬가지로 매우 단순하며, 실행 시간도 거의 일정하다. 따라서 내부 실행 구조는 파이프라인에 최적화될 수 있다.

이 방식의 핵심은 **명령어 집합이라는 인터페이스는 유지하면서, 내부 구현만 변경**한다는 점이다. 기존 소프트웨어와의 호환성을 잃지 않으면서도, 축소 명령어 집합의 장점을 흡수할 수 있다.

결과적으로 현대의 x86 CPU는 외형상으로는 복잡 명령어 집합이지만, 내부적으로는 축소 명령어 집합과 매우 유사한 구조로 동작한다.

---

## 4.8.2 하이퍼스레딩이라는 필살기

<img width="1648" height="927" alt="image" src="https://github.com/user-attachments/assets/aae9de2f-5348-4bcf-9ca7-b08b4667bb9f" />


복잡 명령어 집합 진영은 또 하나의 중요한 기술을 도입한다. 바로 **하이퍼스레딩(hyper-threading)**이다.

기존에는 CPU가 한 번에 하나의 명령 흐름만 처리할 수 있다고 생각했다. 즉, 하나의 CPU 코어는 하나의 스레드만 실행할 수 있다는 인식이다.

하이퍼스레딩은 이 가정을 깨뜨린다. 하이퍼스레딩이 적용된 CPU에서는 하나의 물리적 코어가 **두 개의 논리적 스레드**를 동시에 처리할 수 있다.

운영 체제는 이를 실제로 CPU 코어가 두 개인 것처럼 인식한다. 하지만 실제 하드웨어적으로는 하나의 코어이며, 내부 자원을 효율적으로 분할해 사용한다.

이 기술의 핵심은 파이프라인의 빈 공간을 활용하는 데 있다. 명령어 간 의존성이나 메모리 지연으로 인해 파이프라인에 빈 구간이 발생하는데, 이 공간을 다른 스레드의 명령어로 채운다.

이를 통해 CPU 자원의 활용률을 극대화할 수 있다.

---

## 4.8.3 장점은 취하고 약점은 보완하다: CISC와 RISC의 통합

이 시점에서 복잡 명령어 집합과 축소 명령어 집합은 더 이상 명확히 구분되지 않는다. 두 진영은 서로의 장점을 적극적으로 흡수하며 점점 닮아가기 시작한다.

복잡 명령어 집합 CPU는 내부적으로 축소 명령어 집합과 유사한 실행 구조를 채택한다. 반대로, 일부 고성능 축소 명령어 집합 CPU에서도 마이크로 명령어와 유사한 내부 처리 방식이 사용된다.

그럼에도 불구하고 두 구조 사이에는 여전히 차이가 존재한다. 축소 명령어 집합은 명령어 길이가 일정하고 LOAD/STORE 구조를 유지하며, 컴파일러의 역할이 매우 중요하다.

복잡 명령어 집합은 여전히 다양한 주소 지정 방식과 가변 길이 명령어를 제공하며, 하위 호환성을 강력한 무기로 삼는다. 하지만 이 차이는 기술적인 본질이라기보다는 **설계 철학의 차이**에 가깝다.

---

## 4.8.4 기술이 전부는 아니다: CISC와 RISC 간 상업적 전쟁

CPU의 승패는 기술력만으로 결정되지 않는다. 소프트웨어 생태계, 시장 점유율, 기업 간 동맹 역시 결정적인 요소이다.

x86 진영은 막대한 소프트웨어 자산과 호환성을 기반으로 데스크톱과 서버 시장을 장악했다. 인텔과 마이크로소프트를 중심으로 한 생태계는 강력한 네트워크 효과를 만들어냈다.

반면 축소 명령어 집합 진영은 모바일과 저전력 시장에서 강점을 보였다. 특히 ARM 계열 프로세서는 낮은 전력 소비를 무기로 스마트폰과 임베디드 시장을 지배하게 된다.

이후 애플은 ARM 기반 프로세서를 데스크톱 영역으로 끌어올리며 새로운 변화를 만들어냈다. 이는 과거 인텔이 x86으로 이뤄냈던 성공을 다시 재현한 사례로 볼 수 있다.

결국 복잡 명령어 집합과 축소 명령어 집합은 각자의 영역에서 공존하며 경쟁하는 구조가 되었다.

---

# 4.9 CPU: 스택과 함수 호출, 시스템 호출, 스레드 전환, 인터럽트 처리

컴퓨터 시스템에서 함수 호출, 시스템 호출, 스레드 전환, 인터럽트 처리는 모두 **프로그램의 실행 흐름을 중단했다가 다시 이어서 실행하는 구조**이다.

이러한 기능들이 가능한 이유는 CPU가 **현재 실행 상태를 저장하고 복원할 수 있기 때문**이다.

이 장의 핵심은 **CPU는 실행 흐름을 기억하고, 바꾸고, 다시 되돌릴 수 있다**는 점이다.

---

## 4.9.1 레지스터

레지스터는 CPU 내부에 존재하는 가장 빠른 저장 공간이다.

CPU가 메모리에 직접 접근하는 속도는 레지스터 접근 속도에 비해 매우 느리기 때문에, 계산에 필요한 데이터는 반드시 레지스터로 옮겨 처리해야 한다.

프로그램이 실행되면 코드와 데이터는 메모리에 존재하지만, 실제 명령어 실행 시에는

- 연산 대상 데이터
- 중간 계산 결과
- 실행 상태 정보
    
    를 레지스터에 임시로 저장한다.
    

레지스터와 메모리는 본질적으로 정보를 저장한다는 점에서는 같지만,

레지스터는 속도가 빠르고 용량이 작으며, 메모리는 느리지만 용량이 크다는 차이가 있다.

---

## 4.9.2 스택 포인터(Stack Pointer)

모든 함수 호출은 **스택 프레임(stack frame)**을 가진다.

스택 프레임은 함수 실행 중 필요한 로컬 변수, 매개변수, 반환 주소 등을 저장하는 공간이다.

스택 포인터는 **현재 스택의 최상단(stack top)**을 가리키는 레지스터이다.

함수가 호출되면 스택 포인터는 이동하며 새로운 스택 프레임이 생성되고,

함수가 종료되면 스택 포인터는 이전 위치로 되돌아간다.

함수 호출이 깊어질수록 스택 프레임은 쌓이며,

함수 반환은 반드시 **후입선출(LIFO)** 순서로 이루어진다.

---

## 4.9.3 명령어 주소 레지스터 (PC)

CPU는 메모리에 있는 수많은 기계 명령어 중 **어떤 명령어를 실행해야 하는지**를 알아야 한다.

이를 위해 사용하는 레지스터가 **명령어 주소 레지스터**이다.

이 레지스터는 보통

- PC(Program Counter)
- IP(Instruction Pointer)
    
    라고 불린다.
    

PC에는 **다음에 실행할 명령어의 메모리 주소**가 저장된다.

CPU는 PC가 가리키는 주소에서 명령어를 가져와 실행하고, 일반적으로 PC 값을 증가시킨다.

분기, 점프, 함수 호출, 함수 반환이 발생하면 PC 값은 연속적으로 증가하지 않고 **새로운 주소로 변경**된다.

---

## 4.9.4 상태 레지스터(Status Register)

상태 레지스터는 **CPU의 현재 상태를 나타내는 정보**를 저장한다.

여기에는 다음과 같은 정보가 포함된다.

- 산술 연산 결과의 상태 (carry, overflow 등)
- 조건 분기 판단을 위한 플래그
- CPU가 사용자 모드인지 커널 모드인지에 대한 정보

이 레지스터를 통해 CPU는

“지금 어떤 상태에서 실행 중인가”를 스스로 인식한다.

사용자 프로그램은 사용자 모드에서 실행되며,

운영체제 커널 코드는 커널 모드에서 실행된다.

이 모드 전환 역시 상태 레지스터를 통해 관리된다.

---

## 4.9.5 상황 정보(Context)

상황 정보란 **프로그램이 특정 시점에 어떤 상태로 실행되고 있었는지에 대한 전체 정보**이다.

상황 정보에는 다음이 포함된다.

- 레지스터 값들
- PC 값
- 스택 포인터
- 상태 레지스터 값

CPU는 다음과 같은 상황에서 실행 흐름을 중단할 수 있다.

1. 함수 호출
2. 시스템 호출
3. 스레드 전환
4. 인터럽트 처리

이때 CPU는 **현재 상황 정보를 저장**해 두지 않으면,

나중에 어디서부터 다시 실행해야 할지 알 수 없다.

---

## 4.9.6 중첩과 스택

프로그램의 실행 흐름은 단순히 직선적이지 않다.

함수 안에서 또 다른 함수가 호출되고,

그 안에서 다시 다른 작업이 발생한다.

이처럼 **중첩된 실행 구조**를 처리하기 위해 스택이 사용된다.

스택은

- 실행 순서를 자연스럽게 관리할 수 있고
- 가장 최근에 실행된 작업부터 복원할 수 있는
    
    구조를 제공한다.
    

---

## 4.9.7 함수 호출과 실행 시간 스택

함수를 호출하면 CPU는

- 반환 주소
- 레지스터 상태
    
    를 스택에 저장한다.
    

각 함수는 자신만의 스택 프레임을 가지며,

함수 호출이 끝나면 스택 프레임이 제거되고 이전 함수로 복귀한다.

이 과정은 모두 **실행 시간 스택(runtime stack)**을 통해 관리된다.

---

## 4.9.8 시스템 호출과 커널 상태 스택

시스템 호출(system call)은 **사용자 프로그램이 운영체제에게 직접 할 수 없는 작업을 대신 요청하는 방식**이다.

예를 들어 파일을 열거나, 디스크에 접근하거나, 새로운 스레드를 생성하는 작업은 사용자 프로그램이 직접 수행할 수 없다.

이러한 작업은 **운영체제(커널)**만 수행할 수 있기 때문에,

사용자 프로그램은 시스템 호출을 통해 커널에게 처리를 요청한다.

---

### 시스템 호출이 발생하면 무슨 일이 일어날까?

프로그램은 처음에 **사용자 상태(user mode)**에서 실행된다.

사용자 상태에서는 CPU가 실행할 수 있는 명령어가 제한되어 있다.

시스템 호출 명령어가 실행되면 CPU는 다음과 같은 일을 한다.

1. CPU는 **사용자 상태에서 커널 상태(kernel mode)로 전환**한다
2. 사용자 상태에서 사용하던 레지스터 값과 실행 상황 정보를 저장한다
3. 커널 코드의 시작 지점으로 실행 흐름을 이동한다

이때 중요한 점은 **사용자 상태에서 쓰던 스택을 그대로 사용하지 않는다**는 것이다.

---

### 커널 상태 스택이 필요한 이유

커널 역시 내부적으로 함수 호출을 수행하고,

지역 변수와 반환 주소를 저장해야 한다.

하지만 커널은 사용자 프로그램과 **완전히 분리된 환경**에서 실행되어야 한다.

그래서 시스템 호출이 발생하면 CPU는

- 사용자 상태 스택 → 사용 중단
- **커널 상태 스택(kernel mode stack)** → 사용 시작

이라는 전환을 수행한다.

즉,

- 사용자 상태 스택은 사용자 프로그램 전용
- 커널 상태 스택은 커널 코드 전용

으로 **명확히 분리되어 있다**.

---

### 시스템 호출 처리 과정 정리

시스템 호출의 전체 흐름은 다음과 같다.

1. 사용자 프로그램이 시스템 호출 명령어 실행
2. CPU가 커널 상태로 전환
3. 사용자 실행 상태(Context)를 **커널 상태 스택에 저장**
4. 커널 코드가 커널 상태 스택을 사용하며 시스템 호출 처리
5. 시스템 호출 처리 완료
6. 저장해 두었던 사용자 상태를 복원
7. CPU가 다시 사용자 상태로 전환
8. 사용자 프로그램이 중단 지점 이후부터 계속 실행

---

### 핵심 포인트

- 시스템 호출은 **모드 전환(user → kernel)**을 반드시 포함한다
- 이 전환 과정에서 **커널 상태 스택이 사용된다**
- 사용자 스택과 커널 스택은 절대 섞이지 않는다
- 시스템 호출의 본질은 **“실행 흐름은 유지한 채, 실행 권한만 잠시 커널로 넘기는 것”**이다

---

## 4.9.9 인터럽트와 인터럽트 함수 스택

인터럽트는 프로그램이 실행 중일 때 발생하는 **비동기적 사건**을 처리하기 위한 메커니즘이다. 키보드 입력, 마우스 이동, 네트워크 패킷 수신, 타이머 만료와 같은 사건은 프로그램의 실행 흐름과 무관하게 발생하며, CPU는 이를 무시하지 않고 즉시 대응해야 한다. 이를 위해 CPU는 현재 실행 중인 프로그램의 흐름을 잠시 중단하고, 인터럽트 처리를 위한 별도의 실행 경로로 전환한다.

인터럽트의 본질은 **현재 CPU 실행 흐름을 끊고(interrupt)**,

**정해진 인터럽트 처리 함수로 점프한 뒤**,

**처리가 끝나면 원래 실행하던 위치로 복귀하는 것**이다.

---

### 인터럽트 발생 시 CPU의 동작 흐름

인터럽트가 발생하면 CPU는 다음과 같은 순서를 따른다.

1. 현재 실행 중이던 명령의 흐름을 중단한다.
2. 현재 CPU 상태를 저장한다.
3. 사용자 상태에서 커널 상태로 전환한다.
4. 인터럽트 처리 함수(ISR, Interrupt Service Routine)의 시작 주소로 점프한다.
5. 인터럽트 처리 함수 실행을 완료한다.
6. 저장해 두었던 CPU 상태를 복원한다.
7. 다시 사용자 상태로 돌아가 기존 프로그램 실행을 재개한다.

단답형으로 정리하면 다음과 같다.

- 인터럽트는 CPU 실행 흐름을 강제로 중단시킨다
- 인터럽트 처리는 커널 모드에서 수행된다
- 처리 후에는 반드시 원래 실행 위치로 복귀한다

---

### 인터럽트 처리 함수와 스택의 필요성

인터럽트 처리 함수 역시 함수이기 때문에 실행 중 필요한 정보를 저장할 공간이 필요하다. 지역 변수, 임시 계산 결과, 레지스터 백업 정보 등은 모두 실행 시간 동안 어딘가에 저장되어야 한다. 따라서 인터럽트 처리 함수도 **실행 시간 스택을 필요로 한다**.

여기서 중요한 점은,

인터럽트는 사용자 프로그램의 요청이 아니라 **외부 사건에 의해 발생**한다는 것이다.

따라서 인터럽트 처리 중에는 사용자 프로그램의 스택을 사용해서는 안 된다.

결론적으로,

- 인터럽트 처리 함수는 사용자 스택을 사용하지 않는다
- 인터럽트 처리 함수는 **커널 상태 스택(kernel mode stack)**을 사용한다

---

### 인터럽트 함수 스택의 두 가지 구현 방식

인터럽트 처리 함수의 실행 시간 스택은 시스템에 따라 두 가지 방식으로 구현될 수 있다.

첫 번째 방식은 **인터럽트 처리 함수가 별도의 스택을 가지지 않는 경우**이다.

이 경우 인터럽트 처리 함수는 기존의 커널 상태 스택을 그대로 사용한다.

즉, 시스템 호출 처리와 동일한 커널 스택 위에서 인터럽트 처리가 이루어진다.

두 번째 방식은 **인터럽트 처리 전용 스택(ISR 스택)을 두는 경우**이다.

이 방식에서는 각 CPU가 자신만의 인터럽트 처리 전용 스택을 가지며, 인터럽트가 발생하면 해당 스택으로 전환한 뒤 인터럽트 처리 함수를 실행한다.

단답형으로 정리하면 다음과 같다.

- 인터럽트 스택 구현 방식은 시스템마다 다를 수 있다
- 커널 스택을 공유하는 방식이 있다
- CPU별 ISR 전용 스택을 사용하는 방식도 있다

---

### 인터럽트와 시스템 호출의 차이

인터럽트 처리 흐름은 시스템 호출과 매우 유사하다.

둘 다 사용자 상태에서 커널 상태로 전환되고, 커널 스택을 사용하며, 처리가 끝나면 다시 사용자 상태로 복귀한다.

하지만 결정적인 차이점이 있다.

- 시스템 호출은 **사용자 프로그램이 명시적으로 요청**한다
- 인터럽트는 **외부 장치나 하드웨어에 의해 강제로 발생**한다

즉,

- 시스템 호출: 동기적, 예측 가능
- 인터럽트: 비동기적, 예측 불가능

---

### 인터럽트 처리의 요약

인터럽트 처리는 CPU 실행 흐름을 일시 중단하고 커널 모드에서 인터럽트 처리 함수를 실행한 뒤, 이전 상태를 정확히 복원하는 과정이다. 이 과정이 가능하기 위해서는 CPU 상태 저장과 복원이 필수이며, 이를 위해 커널 상태 스택 또는 인터럽트 전용 스택이 사용된다.

결국 인터럽트 역시

**CPU 상태 저장 → 처리 → 상태 복원**이라는 큰 틀에서,

앞에서 배운 함수 호출, 시스템 호출, 스레드 전환과 같은 구조를 공유한다.
