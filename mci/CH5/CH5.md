# CH5.캐시

## CH5.1. 캐시 등장의 배경

- 캐시 등장배경: CPU와 메모리의 속도 차가 너무 커서.
- 캐시 계층
    - L1 캐시
    - L2 캐시
    - L3 캐시
- CPU 접근 시간 차 (clk은 클럭 주기 의미)
    - L1 캐시: 4clk
    - L2 캐시: 10clk
    - L3 캐시: 50clk
    - 메모리: ??, (100배 느림)
    - 디스크: 10ms (10만배 느림)
    - 분산시스템
- 캐싱의 대가: 캐시 갱신 문제
    - 고려 대상: 메모리, 디스크
    - 고려 상황: 다중 코어일 경우에는 다중 CPU 코어에 저장된 캐시 갱신도 고려해야 함.
        - 상황: CPU C1과 C2가 동시에 메모리의 X=4 변수를 각 캐시에 적재했다면, C1은 이제 **메모리와 추가적으로** **C2의 캐시** 둘다 갱신해줘야 함.
        - 해결법: MESI 프로토콜 (컴퓨터구조시간에 배운. 캐시데이터에 수정/배타/공유/무효 상태를 부여하여 일관성을 관리하는 방법)
- 캐시 갱신 문제의 해결법
    1. 연속기입법 (write-through)
        
        캐시 갱신과 메모리 갱신을 연속적으로 하는 것. 그러나 CPU가 메모리 갱신이 될때까지 기다려야 한다면 캐시 사용의 의미가 없겠지.. 따라서 비동기적으로(기다리지 않음) 설계되어 있음.
        
    2. 후기입 (write-back)
        
        캐시에서 제거할 때, 만약 수정된 적이 있다면 메모리 갱신하는 것
        
- 메모리의 디스크 캐시 활용
    - 가능한 이유: 메모리가 점점 저렴해지고 있음. 2TB 메모리를 가진 인스턴스도 나올 정도. 이정도면 메모리 전체를 디스크로 사용하는 게 가능하다.
    - 정의: 여유메모리 공간에 디스크에서 입출력한 파일을 적재하는 것. → 리눅스의 `페이지 캐시` 원리이기도 함.
    - 한계: 메모리가 완전히 디스크를 대체할 순 없다. 당연하지만 메모리는 영구저장이 불가능하기 때문이다.
- 가상메모리와 디스크 (더 좋은 제목이 있을 듯..)
    - 디스크가 메모리의 창고 역할을 해주면서, `모든 프로세스가 차지하는 메모리의 크기 > 실제 물리적 메모리의 크기`가 된 것을 의미함.
    - 예시: 1번부터 N번 프로세스가 이미 실제 물리 메모리를 모두 점유하고 있는 와중, `N+1번` 프로세스도 메모리를 요청 → 거절하는 게 아니라 디스크에 1~N번 중 안쓰는 프로세스 옮기고 해당 데이터를 `N+1번` 프로세스에게 준다.
    
    → 여기서 나아가 분산시스템까지도 메모리의 연장선으로 사용이 가능함.
    
- 전반적 시스템 (운영체제가 가상물리를 사용하는 경우)
    
    ## CH5.1. 캐시 등장의 배경

- 캐시 등장배경: CPU와 메모리의 속도 차가 너무 커서.
- 캐시 계층
    - L1 캐시
    - L2 캐시
    - L3 캐시
- CPU 접근 시간 차 (clk은 클럭 주기 의미)
    - L1 캐시: 4clk
    - L2 캐시: 10clk
    - L3 캐시: 50clk
    - 메모리: ??, (100배 느림)
    - 디스크: 10ms (10만배 느림)
    - 분산시스템
- 캐싱의 대가: 캐시 갱신 문제
    - 고려 대상: 메모리, 디스크
    - 고려 상황: 다중 코어일 경우에는 다중 CPU 코어에 저장된 캐시 갱신도 고려해야 함.
        - 상황: CPU C1과 C2가 동시에 메모리의 X=4 변수를 각 캐시에 적재했다면, C1은 이제 **메모리와 추가적으로** **C2의 캐시** 둘다 갱신해줘야 함.
        - 해결법: MESI 프로토콜 (컴퓨터구조시간에 배운. 캐시데이터에 수정/배타/공유/무효 상태를 부여하여 일관성을 관리하는 방법)
- 캐시 갱신 문제의 해결법
    1. 연속기입법 (write-through)
        
        캐시 갱신과 메모리 갱신을 연속적으로 하는 것. 그러나 CPU가 메모리 갱신이 될때까지 기다려야 한다면 캐시 사용의 의미가 없겠지.. 따라서 비동기적으로(기다리지 않음) 설계되어 있음.
        
    2. 후기입 (write-back)
        
        캐시에서 제거할 때, 만약 수정된 적이 있다면 메모리 갱신하는 것
        
- 메모리의 디스크 캐시 활용
    - 가능한 이유: 메모리가 점점 저렴해지고 있음. 2TB 메모리를 가진 인스턴스도 나올 정도. 이정도면 메모리 전체를 디스크로 사용하는 게 가능하다.
    - 정의: 여유메모리 공간에 디스크에서 입출력한 파일을 적재하는 것. → 리눅스의 `페이지 캐시` 원리이기도 함.
    - 한계: 메모리가 완전히 디스크를 대체할 순 없다. 당연하지만 메모리는 영구저장이 불가능하기 때문이다.
- 가상메모리와 디스크 (더 좋은 제목이 있을 듯..)
    - 디스크가 메모리의 창고 역할을 해주면서, `모든 프로세스가 차지하는 메모리의 크기 > 실제 물리적 메모리의 크기`가 된 것을 의미함.
    - 예시: 1번부터 N번 프로세스가 이미 실제 물리 메모리를 모두 점유하고 있는 와중, `N+1번` 프로세스도 메모리를 요청 → 거절하는 게 아니라 디스크에 1~N번 중 안쓰는 프로세스 옮기고 해당 데이터를 `N+1번` 프로세스에게 준다.
    
    → 여기서 나아가 분산시스템까지도 메모리의 연장선으로 사용이 가능함.
- 분산 저장의 지원
    - 원격 분산 파일 시스템의 데이터를 data stream 형태로 끌어올 수 있음. ⇒ 이 경우 오히려 로컬 디스크가 분산 파일 시스템에서 전송한 파일을 저장하므로 “디스크가 분산 파일 시스템의 캐시”로 쓰이는 모양이 된다.
    - 예시: 메시지 미들웨어인 apache kafka → 사용자는 원격 분산 파일 시스템에 저장된 메시지를 실시간으로 소비자에게 전달해준다.
- 전반적 시스템 (운영체제가 가상물리를 사용하는 경우)
    
    <img width="602" height="476" alt="image" src="https://github.com/user-attachments/assets/ef7af2e9-86b9-48db-af75-fd05917f724b" />
