# 3.6 고성능 서버의 메모리 풀은 어떻게 구현될까?

- memory pool 기술로 메모리 할당 전략 구현
- malloc으로 메모리를 요청하면 복잡하고, system call도 발생하며, 빈번한 메모리 할당 해제 요청은 시스템 성능에 영향을 미침

## memory pool vs memory allocator

1. malloc → 표준 library, memory pool → 응용 프로그램의 일부
        
2. malloc → 복잡하지만 범용성이 좋음. memory pool → 간편하지만 특정 상황에서만 메모리 할당 성능 최적화

## memory pool 원리

- 한 번에 큰 메모리 조각 요청 → 이 위에서 자체적으로 메모리 할당, 해제하는 방식으로 표준 library, os 우회
- 사용 패턴에 따른 최적화 가능
    - 서버에서 사용자 요청을 처리할 때 마다 여러 종류의 객체 생성 → Memory pool에 미리 객체 생성, 사용 완료 후 반환

## memory pool 구현

- 한 가지 종류의 객체만 사용한다면 ez

1. 모든 메모리 조각을 연결 리스트로 연결, 포인터를 사용하여 현재 여유 메모리 조각의 위치 기록
    - Free_ptr: 여유 메모리 조각의 시작 위치를 가리키는 pointer
2. 메모리 부족 → malloc로 새 메모리 조각 요청(이미 확보된 memory에서 할당. system call x)
    - 이때 새로운 메모리 조각의 크기는 이전 메모리 조각의 2배
    - memory pool → malloc가 반환한 메모리 위에 재할당
3. 요청 처리가 완료되면 한 번에 전체 memory pool 해제
    - free() 처럼 메모리 조각 해제 기능은 x
    - 한꺼번에 메모리를 해제해서 부담을 최대한 줄임

⇒ 단일 스레드 환경에서는 잘 동작하지만, 멀티스레드 환경에서 Thread-Safe를 보장하려면 어떻게 해야 하는가?

## memory pool의 thread-safe 문제

1. memory pool에 Lock을 건다면?
        
    - 요청이 적을때는 괜찮지만, 많은 양의 스레드가 메모리 할당, 해제 요청(많은 요청이 들어올 때)한다면 race condition 발생 → 시스템 성능 저하
2. 각 thread마다 memory pool을 유지해 thread 간의 race condition 문제를 해결하자
        
    - thread local storage에 memory pool을 넣어, 각 thread가 자신에게 속한 memory pool만 사용하도록 구현
    - 하지만 thread A가 메모리 조각 요청 → 이 메모리의 수명 주기가 thread A보다 짧다면?
            

# 3.7 대표적인 메모리 관련 버그

## 지역 변수의 포인터 반환

```c
int *func()
{
	int a = 2;
	
	return &a;
}

void main()
{
	int* p = func();
	
	*p = 20;

}
```

- 지역변수 a → func stack frame에 위치 → func 함수의 실행이 끝나면 stack frame도 사라짐 → 따라서 main()의 *p는 사라진 변수를 가리킴

## 포인터 연산의 잘못된 이해

```c
int sum(int *arr, int len)
{
	int sum = 0;
	
	for(int i=0;i<len;i++){
		sum += *arr;
		arr += sizeof(int);
	}
	
	return sum;
}
```

- 포인터 연산 → 단위만큼 이동
    - int 형의 pointer 연산 → 1byte가 아닌 4byte(int = 4byte)만큼 이동
- 따라서 포인터를 이동할 때 데이터 형식의 크기를 신경쓰지 않아도 됨

## 문제 있는 포인터 역참조

```c
int a;

scanf("%d", a);
```

- scanf → a 값을 주소로 취급
- 만약 지역변수 a값이 고정되어 있지 않다면?
    1. a값이 code segment 나 읽기 전용 영역을 가리키는 포인터 값으로 해석된다면 → kill process
    2. a값이 stack area을 가리키는 pointer값으로 해석된다면 → 다른 함수의 stack frame 파괴 → 버그 원인 찾기 어려움
    3. a값이 heap area을 가리키는 pointer값으로 해석된다면 → 프로그램이 동적으로 할당한 memory 파괴 → 버그 원인 찾기 어려움

## 초기화되지 않은 메모리 읽기

```c
void add() 
{
	int* a = (int*)malloc(sizeof(int)); //메모리 초기화 x
	
	*a += 10;
}
```

- malloc 호출 시 → 다른 프로세스에서 정보를 읽지 못하도록 os가 메모리 반환하기 전 초기화를 해 주자
    1. malloc가 충분한 메모리 유지 → 여유 메모리 조각 반환 → 이미 사용된 메모리라면 이전에 사용한 정보가 남아 있을 수 있음
    2. malloc이 유지하는 메모리가 충분 x → brk(system call)로 os에 memory 요청 → 메모리 사용 시 페이지 누락 interrupt 발생 → os가 실제 메모리를 할당하므로 0으로 초기화 되어 있음

## 이미 해제된 메모리 참조

```c
void add()
{
int *a = (int*)malloc(sizeof(int));

free(a);

int b = *a;
}
```

- heap area에 메모리 할당 요청 → 정수 (a) 저장 → 해제
1. pointer a가 가리키는 memory 조각이 해제된 후 → malloc로 다시 할당하지 않았다면 a가 가리키는 값은 이전과 동일
2. pointer a가 가리키는 memory 조각이 malloc로 할당되었다면 → a가 가리키는 값은 이미 덮어쓰기가 되었을 수 있음
- 이미 해제된 메모리 조각을 참조하지 않도록 코드를 작성하자

## 배열 첨자는 0부터 시작

```c
void init(int n)
{
	int* arr = (int*)malloc(n * sizeof(int));
	
	for(int i=0;i<=n;i++) {
		arr[i] = i;
	}

}
```

- 할당 연산 n+1번 수행 → arr 배열 뒤 메모리를 i로 덮어씀
1. malloc가 arr에 반환한 메모리가 n*sizeof(int)보다 크다면 덮어써도 문제 발생 x
2. 하지만 덮어쓴 메모리에 malloc이 사용하는 메모리 할당 상태 정보가 있다면 동작을 파괴할수도..
- 결론은 딱 쓸 만큼만 할당 받아라

## stack overflow

```c
void buffer_overflow()
{
	char buf[32];
	gets(buf);
	
	return;
}
```

- 사용자 입력이 32byte 초과하지 않는다 가정
    - 하지만 초과한다면? → stack frame 인접한 데이터 파괴
    - 고전적인 해킹 방법에서 사용
        1. 모든 함수는 실행 시 스택 영역에 자신만의 스택 프레임을 가지고, 함수의 반환 주소는 스택 프레임에 저장
        2. 함수 실행 완료 → 스택 프레임에 저장된 반환 주소를 기준으로 이전 함수로 돌아감
        3. 하지만 스택 버퍼 넘침 문제가 발생한다면 → stack이 넘치는 부분이 stack frame의 반환 주소를 덮어쓰게 됨(악성 코드를 심어둔 주소일수도..)

## memory leak

```c
void memory_leak()
{
	int *p = (int *)malloc(sizeof(int));
	
	return;
}
```

- 메모리가 프로세스 종료 전 까지 해제 x → memory leak 발생 → process의 heap area가 점점 늘어나 os가 강제로 process kill(OOM)
- 이 문제를 방지하려면?
    1. malloc, free 사용 상황 추적 → 하지만 프로그램 실행 속도가 느려지고 재컴파일 필요할수도
    2. linux perf 사용 → page fault가 발생한 함수 호출 스택 추적 → 이걸 분석해서 memory leak 방지
        - page fault: heap area 부족해서 확장 할 때 할당된 메모리를 사용하려고 하면 발생 → heap이 부족하다 = memory leak의 여지가 있다

# 3.8 왜 SSD는 메모리로 사용할 수 없을까?

## 메모리 읽기/쓰기 vs 디스크 읽기/쓰기

- file 크기 → 할당된 조각과 관련
    - 실제 사이즈는 5.72 KB이지만, 파일이 disk block에 저장되므로 → 실제 차지 공간은 8KB
- memory
    - byte 마다 메모리 주소 부여 → CPU가 이 주소를 이용해 해당 내용에 접근
- SSD
    - 조각 단위로 데이터 관리 → 조각 크기가 다양함
    - CPU는 file의 특정 byte에 직접 접근 x → SSD, disk에서 프로그램 실행 x

## 가상 메모리의 제한

- OS 메모리 관리 → 가상 메모리 기반
- 32bit system 최대 주소 지정 범위 → 4GB → 1TB SSD를 메모리로 사용해도 process는 4GB 이상의 메모리 사용 못함
    - 64비트 시스템에서는 문제 없을수도?

# 4.1 이 작은 장난감을 CPU라고 부른다

## 트랜지스터

- switch → 전류가 흐르면 1, 흐르지 않으면 0

## 논리곱, 논리합, 논리부정

- 논리곱 게이트
    - AND
- 논리합 게이트
    - OR
- 논리부정 게이트
    - NOT

## 논리적 완전성

- 논리곱, 논리합, 논리부정 게이트로 모든 함수를 표현할 수 있다

## 가산기

- CPU → 2진법
    - 00 → 0, 자리 올림수 0
    - 01 → 1, 자리 올림수 0
    - 10 → 1, 자리 올림수 0
    - 11 → 0, 자리 올림수 1
- 논리곱 게이트 + 배타적 논리합 게이트를 이용해 이진수 덧셈 구현
        
- CPU에서 계산을 담당하는 모듈 → ALU

## 레지스터

- 부정 논리곱 게이트 2개 조합해 정보를 기억하는 회로를 만들 수 있음 → 논리곱 연산 처리 후 논리부정 연산 처리
        
    - S = 0 → a는 항상 1 → 회로에 1이 저장
    - R = 0 → a는 항상 0 → 회로에 0이 저장
- WE → 저장 여부 선택하는데 사용(1bit) → WE값에 따라 값을 저장할지, 말지 결정
        
- 값 저장 회로를 이어붙인 것 → register
        
- 메모리가 휘발성인 이유 → 이 회로는 전원이 연결되어 있을때는 정보를 저장할 수 있지만, 전원이 끊기면 정보는 모두 사라짐

## 하드웨어, 소프트웨어, 범용 장치

- 하드웨어는 가장 기본적인 기능만 제공하고
- 소프트웨어로 연산 논리를 표현하자
- 컴퓨터가 범용 장치인 이유?
    - 하드웨어는 동일하지만, 소프트웨어에 따라 다른 기능을 제공하기 때문

## 하드웨어 기본 기술: 기계 명령

- 기계 명령어를 통해 CPU에게 어떤 연산을 수행할 지 알려줄 수 있음
    - 하지만 기계 명령어가 너무 많음 → CPU는 덧셈 연산만, 프로그래머가 피연산자를 제공해 다양한 연산을 수행하자

## 소프트웨어와 하드웨어 간 인터페이스: 명령어 집합

- instruction set → opcode + operand
    - opcode: CPU가 실행할 수 있는 명령어
        - sw ↔ hw가 통신하는 interface
    - operand: 각 명령어에 필요한 피연산자

```markdown
ADD(4bit) R6 R2 R6

```

- 처음 4bit → CPU에 수행할 작업(opcode)
    - 2^4 = 16개의 opcode를 가질 수 있음
- 다음 12bit → CPU에 어떻게 작업을 해야 하는지 알려줌
- 이러한 기계어들 번역 도구 → compiler

## 회로에는 지휘자가 필요하다

- clock signal 을 통해 회로가 함께 작업할 수 있도록 조정하거나 동기화함
- clock rate → 1초 동안의 clock signal → clock rate가 높을수록 cpu가 1초에 더 많은 작업을 할 수 있음
- clock rate을 높이려면?
    
    

# 4.2 CPU는 유휴 상태일 때 무엇을 할까?

## 컴퓨터의 CPU 사용률

- 일반적인 CPU 사용률 = 7~8%
- process는 interrupt가 발생해야 wakeup → 나머지 cpu time은 어디로?

## 프로세스 관리와 스케줄링

- System Idle Process → 높은 양의 CPU 사용률 → 이 process의 존재 이유?
- OS는 프로세스 스케줄링을 통해 process를 관리
    - process에 우선순위를 할당하고 → 이 순서에 따라 scheduler가 scheduling을 할 수 있도록 ready queue에 process를 push

## 대기열 상태 확인: 더 나은 설계

- ready queue가 비어 있음 = os가 스케줄링 해야 하는 프로세스가 없음 = CPU가 유휴 상태에 있음
- System Idle Process
    - if-else 문 대신 linked list sentinel node로 구현
        - if-else문 예외 처리를 없애서 코드의 복잡도 줄이기 위해 사용(kernel은 if 같은 예외 처리 구문이 많기 때문..)
        - linked list sentinel node로 구현한 ready queue를 가득 채워 scheduler가 항상 실행할 수 있는 process(=system Idle Process)를 찾을 수 있도록 함 → NULL 판단 로직을 제거해 코드 오류 가능성을 줄이고, 구조를 깔끔하게 유지하자
    - 유휴 프로세스
        - 시스템에 스케줄링 가능한 프로세스가 없다면 → linked list 맨 앞, 맨 마지막에 있는 System Idle Process를 꺼내서 실행
        - 항상 ready 상태이고, 우선순위가 가장 낮음

## 모든 것은 CPU로 돌아온다

- halt
    - 시스템 내 더 이상 실행 준비가 완료된 프로세스가 없을 때 실행될 수 있는 명령어 → halt 명령어를 지속적으로 실행하는 순환을 통해 유휴 프로세스 실행
    - CPU 내부의 일부 모듈을 절전 상태로 전환
    - kernel mode에서 CPU로만 실행될 수 있음
    - suspended와 다르다
        - sleep() → 해당 함수를 호출한 프로세스만 일시 중지

## 유휴 프로세스와 CPU의 저전력 상태

- 순환 구조에서 halt 실행 → 유휴 프로세스 실행
- 코드
    
    ```c
    while(1) {
    	while(!need_resched()) {
    		cpuidle_idle_call();
    	}
    }
    ```
    
    - cpuidle_idle_call()
        - halt 명령어 실행
- kernel은 시스템 유휴 시간을 예측하고, 이에 따라 어떤 수면 상태로 진입할지 결정해야 함

## 인터럽트

- while(1) 무한 loop를 os가 빠져나오는 방법 + single-core cpu에서 유휴 프로세스가 무한 순환 중이어도 다른 프로그램이 정상적으로 응답하는 이유 → timer interrupt 때문
- os는 일정 시간마다 timer interrupt 생성 → cpu는 인터럽트 신호 감지 → os 내부의 인터럽트 처리 함수 실행
    - process가 ready 상태라면 suspended()된 process 재실행
    - process가 준비되지 않은 상태라면 프로세스를 일시 중지시키고, 스케줄러는 준비 완료 상태인 다른 프로세스 스케줄링
- 유휴 프로세스가 timer interrupt로 일시 중지 → interrupt 처리 함수는 시스템에 준비 완료된 프로세스가 있는지 확인 → 없다면 유휴 프로세스 계속 실행

# 4.3 CPU는 숫자를 어떻게 인식할까?

- 컴퓨터 시스템 → 저수준 계층이 트랜지스터로 구성 → 2진법

## 부호-크기 표현

- 양수의 최상위 비트를 1로 바꾸면 → 음수
- 양수 → 0010, 음수 → 1010
- 하지만 0과 -0 둘다 표시 → 공간이 아까움

## 1의 보수

- 양수 반전 → 음수
- 0010 → 2, 1101 → -2
- 하지만 0과 -0 둘다 표시 → 공간이 아까움
- 더하기 연산이 쉽지 않다

## 2의 보수

- 현대 컴퓨터 시스템에서 주로 사용
- -0이 없음
- 양수 → 0010(2)
- 음수 → 1110

## CPU는 정말 숫자를 알고 있을까?

- 2의 보수는 사람에게 직관적이지 않지만, 회로 설계가 단순해진다
    - 가산기는 두 비트의 배타적 논리합 연산이 덧셈의 결과라는 것과 두 비트의 논리곱 연산이 자리 올림수라는 것만 알고 있음
- 프로그래머가 코드 작성 → 컴파일러가 기계어로 변환 → CPU 계산 → 계산 결과를 소프트웨어가 해석 → 사용자에게 응용 프로그램 제공

# 4.4 CPU가 if 문을 만났을 때

- sort 되지 않은 array를 연산하는 경우의 소요 시간 >>>sort 된 array를 연산하는 경우의 소요 시간(약 3배)
- linux perf로 프로그램이 실행 중일 때 CPU 관련 정보를 확인할 수 있다

## CPU Pipeline

- 명령어 인출, 명령어 해독, 실행, 다시 쓰기 4가지 단계를 별도의 하드웨어로 병렬적으로 처리 → 처리 효율이 매우 올라감

## If가 Pipeline을 만나면

- if 명령어 실행이 아직 끝나지 않았지만 → 후속 명령어가 pipeline에 진입
    - if문에 이어지는 후속 명령어의 경우 CPU가 미리 예측한 명령어
- 그렇다면 CPU가 가능한 후속 명령어를 올바르게 추측하는 방법?
    - 프로그램 실행 이력 등으로 예측
        - 만약 array가 sort 되어 있다면 → 결과가 규칙적 → CPU의 예측이 맞을 확률 증가 → 빠른 연산 속도
    - 예측이 실패한다면 → 성능 손실 발생
    - 프로그래밍 언어의 likely/unlikely macro가 compiler에 가능성이 더 높은 분기를 알려주면 → compiler는 결과를 예측해 최적화를 한다
- **분기 예측이 병목의 원인이 아닌지 확인해 보자!** (하지만 분기 예측 실패와 관련된 성능 감소 문제는 거의 신경쓰지 않아도 됨)

# 4.5 CPU core 수와 therad 수 사이의 관계

- CPU가 user mode에서 실행하는 명령어 → thread에 속해 있음
- cpu core 수와 thread 수에는 필연 관계는 없음 → 따라서 메모리가 충분하고, os에 제한이 없다면 single-core system에서도 많은 thread를 생성할 수 있음
- CPU
    - 연산 → PC register 주소에 따라 메모리에서 기계어 꺼내 실행
- OS
    - CPU가 실행하는 명령어가 어떤 스레드에 속하는지 파악

## 작업 분할, blocking I/O

- thread가 특정 작업을 기다리지 않고 진행하고, 높은 동시성을 요구하지 않는 상황이라면, background에서 작업들을 별도의 스레드에 담아 병렬로 처리하자(core 수는 신경쓰지 않아도 됨)
    - single-core cpu
        - 일정 시간 동안 1개의 thread만 실행 가능 하지만 → 여러 개의 작업을 별도의 thread에 배치해서 → os에서 스케줄링, 실행 → 동시에 여러 작업을 실행할 수 있음

## 다중 코어와 다중 스레드

- 단일 코어 성능의 한계 → 다중 코어의 등장
- 다중 프로세스?
    - 다중 코어를 최대한 활용할 수 있지만 process간 통신, process switch에 대한 비용이 크다
- 다중 스레드
    - 다중 코어를 최대한 활용하려면 → 코어 수와 스레드 수가 선형 관계여야 함
    1. 오직 계산(I/O, 동기화 x)
        - core당 thread 1개
    2. 하지만 thread에는 어느 정도의 I/O, 동기화 등이 필요하다
        - 따라서 thread 수를 늘려서 → os가 CPU에 할당할 수 있는 충분한 thread 수를 확보해 성능을 향상시키자
        - 하지만 thread를 너무 많이 생성한다면 → os 성능이 떨어짐
            - 한 스레드에서 → 다른 스레드로 전환할 때 부하가 증가하기 때문
    - 적절한 스레드 수는 테스트를 통해 얻어내자
