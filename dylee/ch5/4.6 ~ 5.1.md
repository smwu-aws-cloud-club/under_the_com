# 4.6 CPU 진화론 - 복잡 명령어 집합

## CPU

- 컴파일러가 프로그램을 기계어로 변환 → 실행 파일 생성 → 프로그램 실행 시 메모리에 실행 파일 적재 → CPU는 이 실행파일의 명령어를 읽어서 실행

## 복잡 명령어 집합

- 복잡 명령어 집합 컴퓨터
    - 처음으로 탄생했던 명령어 집합
    - x86 구조 → intel & amd
- 최초의 프로그램 → 어셈블리어로 직접 작성 → 이걸 바로 CPU가 실행 → 명령어 집합이 풍부해야 하며, 한 개의 명령어가 많은 기능을 제공하는 방향으로 설계
    - 의미상 간격을 이어서 → 더 적은 코드로 많은 작업을 할 수 있는 방향으로 진화
        - 함수 호출, 순환 제어, 복잡한 주소 지정, 데이터 구조, 배열 접근 등 고급 언어와 직접 대응하는 기계어를 만들어 → 기계어와 고급 언어 간 개념의 차이를 줄이는 방향으로 발전
- 하지만 현재는 컴파일러의 발전으로 자연어 ↔ 기계어 해석 가능 → 어셈블리어를 고급 언어로 추상화 하는 방향으로 진화 → 현대 프로그래머는 고급 언어로만 프로그래밍(어셈블리어 몰라도 됨)

## 코드의 저장 공간

### 폰 노이만 구조

- 현대 컴퓨터 구조
- 프로그램, 프로그램의 저장 데이터 → 모두 컴퓨터의 저장 장치 안에 저장될 수 있어야 함
    - 실행 파일 = 기계어 + 데이터
    - 코드 → 실행 시 메모리, 실행 하지 않을 때 디스크에 저장 → **메모리를 효율적으로 사용하려면 기계어를 잘 설계해서 프로그램이 차지하는 저장 공간을 줄여야 함**
        - 따라서 하나의 기계어로 더 많은 작업을 할 수 있고, 기계 명령어 길이가 가변적이며, encoding 해서 메모리 공간을 덜 쓰는 방향으로 복잡 명령어 집합이 발전해 옴

### 복잡 명령어 집합의 한계 - 마이크로코드

- CPU가 명령어들의 집합(회로)가 직접 연결되는 방식으로 설계됨
    - 명령어 실행에는 효율적이나, 유연성이 떨어져 변화에 대응하기 어려움
    - 또한 복잡 명령어 집합의 명령어는 가변적 → 명령어에 복잡한 연산이 포함된다면 CPU 설계, 디버깅 복잡도가 더욱 높아짐
- 이 문제를 해결하기 위해 마이크로코드가 등장함    
    - 하드웨어를 변경하는 것은 어렵지만, 소프트웨어는 쉽게 변경할 수 있다 → 마이크로코드를 이용해 단일 복잡 명령어를 간단한 명령어로 구성된 프로그램으로 정의하자
    - 명령어 추가 시 → 하드웨어의 큰 수정 없이 마이크로코드(소프트웨어)의 수정을 통해 추가할 수 있음
    - CPU 설계 복잡도가 내려감
- 하지만 마이크로코드의 디버깅이 어렵고, 마이크로코드 프로그램 실행 시 트랜지스터를 많이 소모한다는 문제가 있음

# 4.7 CPU 진화론 - 축소 명령어 집합

- 컴파일러의 발전으로, 대부분의 프로그래머는 고급 언어로 프로그램을 작성하기 시작했다.
- 또한 80-20 rule의 등장으로 cpu는 80% 시간 동안 명령어 집합의 기계 명령어 중 20% 실행하며, 컴파일러 설계하는 프로그래머는 고급 언어를 더 간단한 기계 명령어의 조합으로 변환하는 경향이 있고, 복잡한 기계 명령어의 실행 시간 보다 간단한 명령어 집합의 실행 시간이 더 짧음을 확인했다.
- 그렇다면 디버깅이 어렵고 자원을 많이 쓰는 마이크로코드를 쓸 이유가? → 복잡한 명령어를 간단한 명령어 여러 개로 대체하자!

## 축소 명령어 집합

- 간단한 명령어 여러 개로 복잡한 명령어를 구현
    - 마이크로코드 설계 x → cpu 리소스 절약(트랜지스터 절약), 디버깅 굿
- 컴파일러가 CPU에 대해 더 강력한 제어권을 가짐
    - 마이크로코드가 다루던 기계어 → 컴파일러가 해석
- LOAD/STORE 구조
    - 축소 명령어 집합의 명령어는 레지스터 내 데이터만 연산하고
    - LOAD/STORE 명령어만 메모리에 접근 → 읽고 쓰기 담당
- 축소 명령어 집합을 사용하는 프로그램은 복잡 명령어 집합보다 더 많은 저장 공간이 필요함 → 하지만 프로그래머는 어셈블리어로 코드를 작성하지 않고, 명령어 파이프라인을 통해 빠른 cpu 연산이 가능

## 명령어 파이프라인

- 축소 명령어 집합은 간단한 명령어들의 집합
    
    → 명령어 실행 시간이 거의 동일 
    
    → 파이프라인 기술을 통해 실행 효율을 높일 수 있음
    
    → 더 작고 성능좋은 CPU, 더 높은 Clock rate를 가짐 → 동일한 작업을 할 때 복잡 명령어 집합 구조보다 우수함
    

# x86 processor

- x86 processor(intel & amd) → 복잡 명령어 집합 기반 CPU

## 마이크로 명령어

- cpu interface → 복잡 명령어 집합
- implements → 마이크로 명령어
    - 복잡 명령어 집합을 축소 명령어와 최대한 비슷하게 변환한 명령어
    - 명령어마다 실행 시간도 거의 같음 → 파이프라인 기술을 사용해서 실행 효율을 높일 수 있음
- 복잡 명령어 집합의 호환성을 유지 + 축소 명령어 집합의 장점

## 하이퍼스레딩(하드웨어 스레드)

- 하이퍼스레딩이 탑재된 CPU는 core 1개로도 여러 개의 스레드 처리 가능
- 실제는 single-core 이지만 → os가 multi-core로 인식
- 하이퍼스레딩 → CPU 자체 기능 → 하드웨어의 스레드는 os가 인식 x → os는 system에 더 많은 cpu core가 사용 가능하다고 인식

## 복잡 명령어 집합(CISC) vs 축소 명령어 집합(RISC)

- 축소 명령어 집합 → 일정한 길이의 명령어 → 컴파일러 최적화 굿
    - 복잡 명령어에는 lw, sw 없음
- 현대 컴퓨터에서 복잡 명령어 집합과 축소 명령어 집합 구현의 기술적 차이점은 크지 않음
- 하지만 과거 윈도우 + 인텔 → x86 기반(cisc)
- mac → arm 기반 → 모바일 시대가 오며 스마트폰은 arm 프로세서 기반의 processor을 많이 사용하게 됨 → arm 기반 M1 등장

# 4.9 CPU, 스택과 함수 호출, 시스템 호출, 스레드 전환, 인터럽트 처리 통달하기

- 함수 호출 → 코드 재사용성 개선
- 시스템 호출 → 프로그래머가 os에 요청을 보낼 수 있음
- 멀티태스킹 → 프로세스, 스레드 전환
- 인터럽트 → os가 외부 장치 관리

## 레지스터

- cpu가 제일 빨리 접근할 수 있는 메모리
- 읽기, 쓰기 속도가 매우 빠르지만 제조 비용도 비쌈 → 작은 용량
- 프로세스 실행 정보 → 메모리, cpu 연산에 사용하는 정보 → 레지스터

## 스택 포인터

- stack pointer
    - 스택을 가리키는 포인터로 스택 상단 정보는 스택 하단을 가리키는 스택 포인터에 저장
    - 이 포인터를 통해 함수 호출 스택 추적
- stack frame: 함수 실행 시 로컬 변수, 매개변수 저장하는 독립적인 메모리 공간
    - 함수 호출 단계가 깊어질수록 → 스택 프레임 수 증가 → stack frame이 모여 process의 stack area 구성

## 명령어 주소 레지스터(PC)

- 실행할 기계 명령어의 주소를 저장하는 레지스터
    - 일반적인 명령어 → 순차적 → PC 레지스터 값도 순차적
    - if, jump, return → 순차적 x → PC 레지스터 값 연산이 일어났던가?
- CPU는 PC에 저장된 주소에 따라 메모리에서 명령어를 가져와서 실행

## 상태 레지스터

- 산술 연산이 포함된 명령어에서, 연산 시 자리 올림(carry) 또는 넘침(overflow) 발생 시 상태 저장
- cpu 상태 bit로 kernel state, user state 저장 → bit 변경 시 커널 상태 또는 유저 상태로 전환
    - 대부분 응용 프로그램 → user state
    - 커널이 필요한 case(system call등) → kernel state

## 상황 정보

- CPU는 오름차순으로 기계어를 실행하지 않기 때문에 → 상황 정보를 저장 후 → 프로그램을 일시 정지한 후 다른 프로그램을 실행하다가 → 상황 정보를 가져와서 → 해당 프로그램의 실행을 재개해야 함
- CPU가 오름차순으로 기계어를 실행하지 않는 case → context 저장이 필요
    1. method call 
        - jump
    2. system call
        - cpu가 kernel code 실행을 위해 user state → kernel state 전환(system call)
    3. 스레드 전환
        - 프로그램 A의 기계 명령어 실행 상태 → 프로그램 기계어 실행 상태로 전환
    4. interrupt
        - 실행하던 프로그램 중지

## 중첩과 스택

- Stack 자료구조 → LIFO
    - 가장 먼저 시작한 작업은 가장 마지막에 완료
    - method call, system call, 스레드 전환, Interrupt 모두 stack 을 이용해 처리
    - stack → 자료구조 → hw로 구현할수도 있고, sw로 구현할수도 있음

## 함수 호출과 실행 시간 스택

- 함수 호출 시 stack frame에 저장해야 하는 정보
    - 반환 주소, 사용한 레지스터 정보
    - 함수 A가 함수 B 호출 → 함수 A의 stack frame에 실행 정보 저장 → 함수 B 실행 완료 → stack frame 기반으로 함수 A 실행 재개

## 시스템 호출과 커널 상태 스택

- kernel mode stack
    - kernel state에서 실행하는 함수들
    - 운영 체제가 시스템 호출을 완료하는 데 필요한 실행 시간 스택
    - disk I/O → 응용 프로그램은 system call을 통해 os에 작업 요청 → os가 kernel state에서 file open 작업 함수 실행 → 이 함수의 실행 시간은 kernel mode stack에 저장
- 사용자 상태 스레드
    - 사용자 상태 스택 + 커널 상태 스택
    - 사용자 상태 스레드는 커널 상태에 대응하는 커널 상태 스택을 가지고 있음
- system call 과정
    1. 프로그램이 user mode에서 실행
    2. 사용자 상태의 function D의 system call
    3. CPU가 user mode → kernel mode로 상태 전환
    4. 사용자 상태 스레드에 대응하는 커널 상태 스레드 찾기
    5. 실행 상황 정보(사용자 상태 스레드 레지스터 정보 등) → 커널 상태 스택에 저장
    6. cpu는 kernel에서 코드 실행
        1. 이때 kernel 상태 스택은 함수의 호출, 반환에 따라 크기 증가, 감소
    7. system call 완료 시 kernel 상태 스택에 저장된 사용자 상태 프로그램의 context에 따라 cpu 상태 복원 → kernel state에서 user state로 전환
    8. user state에서 프로그램 계속 실행

## 인터럽트와 인터럽트 함수 스택

- CPU의 실행 흐름을 끊고 특정 인터럽트 처리 함수로 점프 → 함수이기 때문에 실행 시간 스택이 있어야 함
    - 프로그램 실행 중에도 인터럽트 작동 방식을 통해 키 입력, 마우스, 네트워크 수신 작업을 처리할 수 있음
- 인터럽트 처리 함수의 실행 시간 스택
    1. 커널 상태 스택을 이용하여 인터럽트 함수 처리
    2. 인터럽트 처리 함수 스택(ISR) 사용
        - cpu가 인터럽트 처리 → cpu 마다 자신만의 ISR 가짐
- 인터럽트 과정
      
    1. CPU가 사용자 상태에서 기계 명령어 실행 → 인터럽트 발생
    2. 프로그램 실행 중단 → 인터럽트 처리 함수로 jump
    3. cpu가 user state → kernel state로 전환 + 커널 상태 스택에 사용자 상태 스레드의 context 저장
    4. CPU는 인터럽트 처리 함수의 시작 주소로 jump → 커널 상태 스택은 함수의 호출, 반환에 따라 크기 증가 및 감소
    5. 인터럽트 처리 함수 실행 완료 시 kernel 상태 스택에 저장된 사용자 상태 프로그램의 context에 따라 cpu 상태 복원 → kernel state에서 user state로 전환 → 사용자 상태 스레드 계속 실행

## 스레드 전환과 커널 상태 스택

- 스레드 전환 과정
    1. 시스템 내부의 타이머가 인터럽트 신호 발생시킴
    2. CPU는 인터럽트 신호 수신 → 현재 스레드 실행 일시 중지
    3. user state → kernel state로 전환 → kernel안의 타이머 인터럽트 처리 프로그램 실행
    4. 타이머 인터럽트 처리 프로그램은 스레드 A에 할당된 CPU 시간 조각이 전부 사용되었는지 확인 
        - 시간이 남았으면 user state로 가서 계속 실행
        - 시간이 다 되었다면 해당 스레드에 다른 작업 할당
- 스레드 전환 작업
    1. 주소 공간 전환
        - 스레드 들이 다른 프로세스에 속해 있다면 → 다른 주소 공간
    2. CPU를 스레드 A에서 스레드 B로 전환
        - 스레드 A의 CPU 상황 정보 저장, 스레드 B의 CPU 상황 정보 복원
        - linux thread의 `test_struct` 가 CPU의 상황 정보 저장

# 5.1 캐시, 어디에나 존재하는 것

- 폰 노이만 구조
    - CPU는 기계어 실행 시 먼저 명령어를 메모리에서 읽어야 하며, 메모리에는 기계어와 명령어에서 사용하는 데이터가 저장되어 있어야 함
    - 하지만 레지스터 용량은 제한적 → CPU는 메모리에 접근해 명령어, 데이터를 가져와야 함
        - CPU와 메모리의 속도를 맞춰야 한다!

## CPU와 메모리의 속도 차이

- CPU와 메모리의 속도가 같아야 제일 성능이 좋다 → 하지만 속도 차이가 계속 벌어지고 있음…
    - CPU 속도 = 메모리 속도/100
- 속도 차이를 보완하기 위해 CPU ↔ 메모리 사이에 cache 존재

## cache

- 비싸고 용량이 작지만 접근 속도가 CPU와 비슷하다 → 따라서 계층형 구조를 통해 CPU의 효율을 높일 수 있다!

### cache 계층

- hierarchy에 따라 용량 증가, 속도 감소
- CPU는 데이터를 가져와야 할 때 윗 계층의 캐시부터 탐색
1. L1 cache
    - 4 clock rate
2. L2 cache
    - 10 clock rate
3. L3 cache
    - 50 clock rate

### cache 갱신

- 불일치 문제
    - cpu가 cache에 기록 → Cache의 데이터는 갱신되었지만 memory에는 예전 데이터가 남아 있는 경우 → Cache 갱신 필요
1. 연속 기입
    - Cache 갱신 시 메모리도 함께 갱신
    - 동기적 방식 → 비동기적 방식으로 최적화 필요
        - cpu가 메모리 갱신될 때까지 대기
    - 비동기적 방식
        - cpu가 cache 갱신이 완료될 때 까지 기다리지 않고 다음 명령어 실행
2. 후기입
    - cache에서 제거된 데이터가 수정된 적이 있다면 → 메모리 갱신
    - 비동기적 방법

## 다중 코어 캐시의 일관성

- 다중 스레드를 지원하는 하드웨어에서는 동기화 문제가 발생할 수 있음
    - core 2개가 동시에 같은 변수 x 사용 → 각 core 마다 각각의 cache를 가짐(변수 x의 복사본도 2개) → core1이 cache 갱신할 때 core2도 갱신 필요
- 해결 방법 - MESI
    - 한 cache에서 갱신된 변수가 다른 cpu core의 cache에도 존재한다면 함께 갱신이 필요하다
        - 변수 Update → cache, memory 확인 → 해당 변수가 다른 CPU core의 cache있는지 확인 후 갱신해 주는 작업 필요

## 메모리를 디스크의 캐시로 활용하기

- 디스크 탐색 시간 → 10ms → 메모리와 cpu에 비해 매우 느리다
- 최신 os는 memory를 disk의 cache로 활용해 메모리와 디스크의 속도 차이를 해결한다
    - page cache
        - 여유 메모리 공간을 disk의 cache로 활용
        - 하지만 캐시 갱신 문제 발생 → I/O library에서는 sync(동기화), flush(캐시 비우기) 함수 제공
- 계층형 구조

- CPU 내부 캐시 → 메모리 데이터 저장
- 메모리 → 디스크 데이터 저장(캐시처럼 사용)
- 최근은 메모리가 저렴해짐(근데 다시 비싸졌는데..) → 따라서 메모리가 디스크를 대체하는게 대세다! → 하지만 메모리는 비영속적이라 완전히 디스크를 대체할 수는 없음!

## 가상 메모리와 디스크

- process의 자체적인 주소 공간 → 물리 메모리의 크기 초과 할 수 있는 이유?
    - process에서 자주 사용하지 않은 memory data를 disk에 기록 → 이 data가 차지하던 물리 메모리 공간 해제 → 다음 프로세스가 메모리 요청 하는 방식으로 메모리를 할당하기 때문
    - 즉, 디스크가 메모리의 일부 작업을 넘겨받아서, 프로세스가 요청하는 메모리 크기는 물리 메모리의 크기를 초과할 수 있다
        - 메모리 사용률이 높다면 → cpu가 program을 실행할 때도 디스크에 접근해야 할수도..

## CPU는 어떻게 메모리를 읽을까?

- 대용량 데이터 저장 → 분산 파일 시스템 사용 → 로컬 디스크를 원격 분산 파일 시스템의 캐시처럼 사용할 수 있음
- 응답 속도를 더 높이기 위해 원격 분산 file system의 data를 data stream 형태로 local computer systemd의 memory로 끌고 올 수 있음
    - apache kafka
        - 대용량 메시지 → 원격 분산 파일 시스템에 저장
        - 실시간으로 consumer에게 data 전달 시 memory를 원격 분산 파일 시스템의 Cache로 사용
- 최신 컴퓨터 시스템의 저장 체계
    - 높은 계층의 저장 용량은 낮은 계층보다 작아야 함
    - program이 Cache 친화적이어야 함
