# 1. 콜백 함수를 철저하게 이해한다

## 1. 콜백이 필요한 이유

- 콜백 함수 코드를 구현해 → 다른 모듈이나 스레드에서 함수를 호출하도록 설계하자
- 그래야 if-else 지옥에서 벗어날 수 있음

## 2. 비동기 콜백

- 호출 thread가 콜백 함수 실행에 의존하지 않는 것

```bash
void real_make_donut(func f) {
	f();
}

void make_donut(func f) {
	thread t(real_make_donut,f)
}
```

- make_donut 호출 → t생성 후 반환
- t는 real_make_donut 실행

## 3. 동기/비동기

- 함수의 동기 호출
    - 함수가 반환한 결과를 획득 해야 다음 함수 호출 가능한 경우
    - 동기 호출 프로그래밍 방식에서는 함수를 호출한 스레드에서 전체 작업 처리
- 함수의 비동기 호출
    - 함수를 매개변수로 전달한다면 → 일종의 비동기 호출에 해당
    - 작업 처리가 두 부분으로 나뉨
        1. 함수를 호출하는 스레드에서 처리되는 작업들
        2. 다른 스레드, 프로세스, 시스템에서 처리되는 작업들 → 호출자만 무엇을 해야할 지 알고 있음
- 콜백 함수의 본질 → 호출자가 알고 있는 정보(데이터, 함수(코드))를 콜백함수에 잘 담아 다른 모듈에 전달하기

## 4. 콜백 함수의 정의

- 콜백 함수: 다른 코드에 매개변수로 전달되는 실행 가능한 코드
- 콜백 함수 작성자 ≠ 함수 호출자
    - 함수 작성자가 thrid-party library 함수 호출할 때 콜백함수 함께 전달 → thrid-party library 함수는 콜백 함수 호출
        - 콜백 함수 지정 이유? → thrid-party library의 작성자가 특정 시기에 어떤 작업을 수행해야 하는지 알 수 없기 때문 → thrid-party library 사용자가 콜백 함수를 구현해 라이브러리에 전달하면, 서드 파티 라이브러리는 특정 시기에 콜백 함수 호출
- 콜백 함수 호출 시점
    - 시스템에서 이벤트 발생 → 콜백 함수 호출
        - 이벤트: 네트워크 데이터 수신, 파일 전송 완료

## 5. 콜백 유형

### 동기 콜백(블로킹 콜백)

- 라이브러리 함수가 반환되기 전에 콜백 함수 실행

### 비동기 콜백(논블로킹 콜백)

- 라이브러리 함수 호출이 즉시 완료되고 일정 시간 후 콜백 함수 실행 → 콜백 함수와 주 프로그램이 서로 다른 스레드 또는 프로세스에서 동시에 실행될 수 있음
- 다중 코어 리소스 더 잘 활용
- 동시성이 높은 시나리오에 적합

## 6. 비동기 콜백 문제: 콜백 지옥

- 동기 콜백으로 구현한다면, 순차적으로 구현하면 되지만 비동기 콜백으로 구현한다면 함수가 중첩될 수 있다

# 2. 동기와 비동기

## 1. 동기 호출

- 일반적으로 함수를 순차적으로 호출한다면 → 동기 방식
- 한 함수의 실행이 완료되고, 프로세스를 반환해야 다음 함수가 실행됨
- I/O의 경우?
    - blocking I/O
    - read 함수 호출 → 파일 읽기 작업 시작 → 최하단 계층에서 system call로 운영 체제에 요청을 보냄 → os는 파일 읽기 작업을 이해 호출 스레드를 일시 중지, kernel이 디스크 내용을 읽어 오면 thread가 다시 wakeup()
- 비효율적

## 2. 비동기 호출

- I/O를 백그라운드 형태로 실행
- read 함수 호출 → 반환 → 백그라운드에서 file 읽기 작업 실행
- 비동기 호출에서 백그라운드에서 실행 중인 작업이 언제 완료되었는지 어떻게 알 것인지?
    1. 호출자가 실행 결과를 전혀 신경 쓰지 않는 경우
        - read 함수 비동기 호출 시 파일 내용 처리하는 함수를 매개변수로 전달 → 콜백 함수가 다른 스레드나 프로세스에서 파일 내용 처리
    2. 호출자가 실행 결과를 반드시 알아야 하는 경우
        - 알림 작동 방식 사용
        - 작업 실행 완료 → 호출자에게 작업 완료를 알리는 신호나 메시지 보내기
        - 스레드 2개를 사용해서 작업하곤 함
        1. 호출자가 사용하는 스레드 → 콜백함수 호출, 이벤트 결과 받기, 작업 실행 완료 통지
        2. 실제 작업이 이루어지는 스레드 → 콜백함수 수행

## 3. 웹 서버에서의 동기/비동기

- 배경 → DB에서만 입/출력 작업 실행, 주 스레드 1개와 데이터베이스 처리 스레드 1개 존재

### 동기 방식

- 메인 스레드에서 요청 수신 → 주 작업들 수행 → 데이터베이스 요청 전송, 결과 반환될 때 까지 대기(blocking, 주 스레드 일시 중지) → 데이터베이스에서 요청 수신 후 데이터베이스 처리한 다음 결과 반환 → 주 작업들이 데이터베이스에서 반환된 결과를 받아 계속 작업 수행 → 최종 결과 반환
- 이때 주 스레드 사이 빈 공간 = 유휴 시간 존재 → 주 스레드는 유휴시간 동안 DB처리가 완료될 때 까지 기다려야 다음 과정을 처리할 수 있음

### 비동기 방식

- DB 처리 요청을 전송하자마자 새로운 사용자 요청 처리
1. 주 스레드가 DB 처리 결과를 신경 쓰지 않는 경우
    - 콜백 함수를 이용해 데이터베이스 스레드가 데이터베이스 처리 한 다음 작업들까지 모두 수행
        - 주 스레드가 데이터베이스 처리 요청을 보낼 때, 데이터베이스 처리 후 할 작업들을 정의한 콜백 함수를 매개변수로 전달 → 데이터베이스 스레드는 데이터베이스 요청을 처리한 후 전달받은 콜백함수를 호출
        - `DB_query(request, handle_DEF_after_DB_query);` → DB thread는 데이터베이스 요청을 처리한 후 직접 `handle_DEF_after_DB_query` 함수 호출
    - 콜백 함수를 통해 데이터베이스 실행 이후 작업을 전달 받아 실행하는 이유?
        - 이 작업들은 DB thread에서 해야 할 작업이 아니기 때문에, DB thread에서는 데이터베이스 처리 후 콜백 함수를 호출해 다음 작업을 주 스레드에 던진다
    - 유휴시간이 사라지고, 주 스레드 + 디비 스레드 동시에 사용해 빠르게 작업 수행 가능 → 시스템 응답 속도가 빨라짐
2. 주 스레드가 데이터베이스 작업 결과에 관심을 가질 때
    - 알림 작동 방식을 이용해 작업 결과를 주 스레드로 전송해야 함
    - 주 스레드 → 주 작업 + 데이터베이스 작업 비동기 호출 + 데이터베이스 작업 완료 알림(이벤트 결과) 받아서 작업 실행
    - 데이터베이스 스레드 → 주 스레드의 호출을 받아 데이터베이스 처리 + DB 작업 완료 후 주 스레드에 작업 완료 통지

# 3. 블로킹/논블로킹

## 1. 블로킹/논블로킹

- 함수 A → B 호출한다 가정
    - 블로킹 → 함수 B를 호출함과 동시에 운영 체제가 함수 A가 실행 중인 스레드나 프로세스를 **일시 중지시킨다면** 함수 B에 대한 호출 방식은 블로킹 방식
    - 논블로킹 → **일시 중지시키지 않는다면** 논블로킹 방식

## 2. 블로킹의 핵심 문제: 입출력

- disk 입/출력 요청 완료 시간 → ms
- CPU clock rate → GHz → disk I/O 시간동안 많은 작업을 수행할 수 있음
- 따라서 thread에서 I/O가 실행되는 동안 CPU 제어권을 다른 스레드에 넘겨 다른 작업을 하고, I/O 작업 완료 시 CPU 제어권을 다시 넘겨받아 다음 작업을 실행
    - CPU 제어권을 넘겨받았다가 → 다시 넘겨받는 시간 동안 스레드나 프로세스는 블로킹되어 일시 중지됨
    - 이때 os는 각 스레드 간에 cpu 사용 시간을 효율적으로 할당해야 함 → 블로킹 입출력 방식이 필요!
- 하지만 너무 시간이 많이 걸리는 I/O 라면? → 호출 스레드 또는 프로세스가 블로킹되며 일시 중지되는 일이 발생
- 호출 스레드가 일시 중지되지 않으면서 입출력 작업을 시작하려면? → 논블로킹 호출

## 3. 논블로킹과 비동기 입출력

- 배경 → 네트워크 데이터 수신,데이터 수신 함수 `recv`(논블로킹)
- `recv` 호출 → os는 `recv` 즉시 반환(스레드 일시 중지 x) → 호출 스레드는 작업 진행, 데이터 수신 작업은 kernel이 처리 ⇒ 두 가지 작업이 병행 처리됨
- 데이터가 언제 수신되었는지 알 수 있는 방법? → 비동기 입출력 방식 사용
    1. 결과 확인 함수 제공 → 이 함수를 호출해 수신 데이터 확인
    2. 데이터 수신 → 스레드에 메시지나 신호 등을 전송하는 알림 작동 방식 사용
    3. `recv` 함수 호출 시 데이터 수신 처리를 담당하는 함수를 콜백 함수에 담아 매개 변수로 전달

## 4. 동기와 블로킹

- 동기 → 반드시 블로킹은 아님
- 블로킹 호출 → 모두 확실한 동기 호출

## 5. 비동기와 논블로킹

- 코드 구현 방식에 따라 비동기 방식을 지향했음에도, 동기 처럼 보일 수 있다 → 이런 형식의 코드는 비효율을 유발한다
    - 책의 `recv` + 콜백 함수 예시
        - while loop로 결과 check → 결과적으로 handler 함수가 block됨

## 6. 고성능 서버 구현?

프로세스, 스레드, 코루틴 + 동기, 비동기, 블로킹, 논블로킹 = 고성능 서버

# 4. 높은 동시성과 고성능을 갖춘 서버 구현

## 1. 다중 프로세스

- linux → fork 방식으로 자식 프로세스 생성
- 요청 처리 방식
    - 부모 프로세스가 사용자 요청 수신 → fork 방식으로 자식 프로세스 생성 → 사용자 요청 처리

### 장점

- 구현이 간단하고, process 마다 격리되어 있어 하나의 프로세스의 오류가 다른 프로세스에 전파 x, 다중 코어 리소스 최대한 활용 가능

### 단점

- 하지만 Process → 주소 공간 격리 → 프로세스 간에 통신이 쉽지 않다
- process생성 시 부담이 크며 프로세스 빈번한 생성, 종료 → 시스템 부담 증가
    - **주소 공간(가상 메모리) 생성/초기화 비용**
        
        새 프로세스는 독립된 메모리 공간을 가져야 해서 페이지 테이블 등 관리 구조가 크게 생김
        
    - **커널 자료구조 생성 비용**
        
        PCB(프로세스 제어 블록), 핸들/FD 테이블, 스케줄링 정보 등 여러 커널 구조를 새로 만들고 정리해야 
        
    - **TLB/캐시 친화성 악화**
        
        프로세스 전환은 주소공간이 바뀌어서 **TLB flush** 같은 비용이 더 커질 수 있음(아키텍처/OS에 따라 정도 차이)
        
    - **(fork일 때) 복제 비용**
        
        전통적인 fork는 부모 프로세스 상태를 복사해서 자식을 만들었기 때문에 무거웠고,
        
        요즘은 보통 **Copy-on-Write(COW)** 로 다 복사하진 않지만
        
        그래도 **페이지 테이블 복사/설정 + COW 관리** 비용은 남아.
        
    - **(fork + exec 패턴) exec 비용**
        
        fork 후 exec로 새 프로그램을 올리면, 실행 파일 로딩/동적 링크/메모리 매핑 등 추가 비용이 붙음
        
- ex) Apache Web Server
    - os 에서 network connetcion 형성 → 요청 마다 미리 만들어 놓은 process 할당(Pre-fork)
    - 하지만 인터넷 수요가 늘어나면서 동시 Connection 요청 증가 → OOM 발생
        - Process 기반 모델은 동시성 증가 시 메모리 압박이 크다!
        - 이 문제를 해결하기 위해 process 1개가 차지하는 리소스 양을 늘렸지만 → 많은 connection에서 요청이 들어오기 시작하면 → CPU core는 계속 Process를 switch 해야 함 → 이 과정에서 context switch가 늘어나 cpu 부하 증가
    
    ![image.png](attachment:acd6a284-773f-4a6c-996e-b9e08812070c:image.png)
    

## 2. 다중 스레드

- 스레드 → 프로세스 간 주소 공간 공유 → 별도의 통신 작동 방식 사용 x

### 장점

- 스레드는 가벼워서 생성, 종료에 부하가 덜 생김
- 각 요청에 대응하는 스레드 생성 → I/O blocking → 다른 스레드에 영향 x

### 단점

- 하나의 thread에 문제 발생 → 강제 종료 → 같은 Process를 공유하는 모든 thread와 process 한꺼번에 강제종료
- thread들은 Process의 리소스 공유 → 공유 리소스 관리 필요 → Mutex, semaphore등이 필요
- 교착상태가 발생할 수 있음
- 한계: C10K문제 → 동시 요청 수가 매우 많다면 다중 스레드로 감당 x
    - 일반적으로 connection 1개 = thread 1개 할당 → thread가 너무 많아져서 메모리를 너무 많이 잡아먹거나(stack, kernel), 엄청난 스케줄링 → Context switching 비용 증가 등등 한계에 봉착
    - spring MVC + Tomcat(Servlet Container)의 한계?
        - 요청당 worker thread 1개를 붙여 처리(thread-per-request)
        - 만약 blocking 상태가 길어진다면(요청이 오래 대기하는 상황) 동시성이 올라가 스레드 수가 많아지고 context switch, memory 부담이 커짐 → 동시성이 높은 상황에서 불리해짐

## 3. 이벤트 순환과 이벤트 구동

- 조건
    1. 이벤트 → I/O관련 이벤트 (사용자 요청, 네트워크 데이터 수신 여부, 파일의 읽기 및 쓰기 가능 여부)
    2. 이벤트 핸들러
- 동작 방식
    - 이벤트 도착 → 이벤트 확인 → event handler 찾아서 → 호출
    - 이벤트의 반복 → event loop
- 문제점
    1. event Source → get Event 하나로 여러 이벤트를 가져오는 방법?
        
        ⇒ input/output multiplexing 이용
        
    2. handler 함수와 event 순환이 동일한 thread에서 실행되어야 하는지?
        
        ⇒ event loop & 다중 thread
        

### input/output multiplexing

- linux, unix → 모든 것을 file로 취급 → program은 모두 file discriptor, socket를 사용하여 입출력 작업
- File descriptor
    - I/O → file
    - network connection을 위한 socket → file
    - process 내에서 해당 Process가 다루는 file목록 → FD index로 관리
        - 표준 입력, 표준 출력, 표준 에러
        - 한 개의 채팅 서버에 1000명의 client가 접속해 있다면? → 하나의 process가 관리하는 FD는 기본 3개 + Client socket 1000개  = 1003개의 파일 관리
- User Space vs Kernel Space?
    - User Space 에서 system call → Kernel Space로 모드 전환(overhead가 크다)
    - User Space: 응용 프로그램 실행 영역, HW 접근 불가/ 권한 제한
        - User Space의 process가 데이터를 수신하는 방법?
            - 소켓 연결을 통해 client에서 데이터를 서버에 보냄
            - 커널은 네트워크 통신으로 들어온 패킷의 정보를 바탕으로 알맞는 소켓을 찾아 수신된 데이터를 그 소켓의 수신 버퍼에 채워넣음
            - 응용 프로그램이 read 요청을 할 때까지 데이터를 가지고 있음
    - Kernel Space: 운영체제 핵심 실행, 모든 HW/리소스 접근 가능, 관리 가능
- 어떤 소켓의 수신 버퍼에 데이터가 수신되었는지 효율적으로 알 수 있을까? → socket에 data가 들어왔다는 사실을 감지하는 행위와, 데이터를 read 하는 행위를 분리하자 → 이 아이디어로 multiplexing이 등장
- 처음 → select I/O multiplexing
    - kernel에서 준비된 File Discription을 받고, 준비된 것에 대해서만 read 요청
    - 처리해야 하는 데이터가 존재하는 process에만 CPU를 점유할 수 있도록 하기
    - 각 socket 구조체에 wait queue를 구현해, wait queue에 해당 소켓에 데이터가 채워지길 기대하는 프로세스를 등록 → 이때 어떤 fd의 socket에 data가 채워졌는지 정보를 주고 받기 위한 수단이 비트맵
    - 한계
        - 비트맵 → 매번 user space, kernel에서 새로 생성 후 주고받음
        - 모든 FD의 socket을 돌면서 데이터가 수신되었는지 확인하고, wait queue에 등록해야 함 → 시간 복잡도 O(N)
        - 유저 스페이스의 소켓 감지 시간 복잡도가 O(N) → 커널에서 보낸 비트맵 전체를 loop을 돌며 하나하나 확인 후 read
- **epoll**
    - 감시 대상인 fd set을 user가 아닌 kernel에서 관리 → kernel 에서는 red-black tree 형태로 저장 → 시간복잡도가 O(log N)까지 줄어듬
    - 트리 구조를 내부에서 계속 가지고 있어 매번 비트맵 생성과 복제 반복의 비효율성 제거
    - 이벤트 발생 FD(도착한 FD)를 Linked List 형태로 관리 → epoll_wait 호출 시 모든 트리를 뒤지지 않고 Ready List에 연결된 데이터들만 확인
    1. epoll_create: 커널 안에 epoll 인스턴스(전용 공간) 생성
    2. epoll_ctl: epoll 인스턴스 내 감시할 FD를 등록/삭제(구독 신청)
    3. epoll_wait: 변화가 생긴 놈들만 받아오기 (결과 수령)
    - 개선점
        1. 커널에서의 O(N) 개선
            1. 레드블랙 트리 기반으로 감시 소켓 등록/삭제/수정 복잡도가 O(log(N))까지 감소
            2. 데이터가 수신된 것을 감지(epoll_wait) 할 때 발생하는 비용이 O(1)까지 감소
            3. 모든 소켓을 순회하며 wait queue에서 프로세스를 지우기 → epoll 인스턴스의 wait queue 하나에서만 프로세스 지우기 
        2. 유저 스페이스에서의 O(N) 개선 - 모든 fd가 나열된 비트맵 순회 → 데이터가 있는 fd만 반환 O(1)로 감소
    - 한계
        - epoll이 아무리 빨라도 데이터를 읽기 위한 read 시스템 콜을 사용 → 시스템 콜을 사용한다는 것 자체가 병목이 되는 상황
        - read()를 호출하면 복사 완료까지 블로킹
- io_uring
    - 시스템 콜을 최대한 사용하지 않는다!
    - 핵심 아이디어: 유저와 커널이 서로 read, write할 수 있는 공유 메모리(mmap) 공간 활용
    - 공유 메모리에 작업 요청용 큐, 작업 완료 통지용 큐를 각각 두기
    - 개선점
        - 감시 요청을 위한 시스템 콜 감소
        - read 요청 여러 개를 하나로 모아 한 번에 요청 - 시스템 콜 감소
        - 커널에서 유저 버퍼에 직접 데이터를 복사해주기 때문에 시스템 콜 감소

### event loop & 다중 thread

- 사용자 요청을 처리하는데 cpu가 시간을 많이 소모한다면, 단일 thread를 사용해 요청 처리 시 blocking
- 다중 코어를 활용하기 위해 다중 스레드를 사용해 작업을 병렬적으로 처리하자
- 이벤트 핸들러, 이벤트 순환은 각각 독립적인 스레드에 배치
- thread pool을 통해 구현하는 것도 가능

## 4. 이벤트 순환 & 입출력

### 입출력 작업에 대응하는 논블로킹 인터페이스가 있는 경우

- 직접 논블로킹 인터페이스를 호출해도 스레드 일시 중지 x → 이벤트 순환에서 직접 호출 가능

### 입출력 작업에 블로킹 인터페이스만 있는 경우

- 이벤트 순환 내에서 어떤 블로킹 인터페이스도 호출 x → 만약 호출한다면 이벤트 순환 스레드 일시 중지

## 5. 비동기와 콜백 함수

- 마이크로 서비스 아키텍처의 등장(서버 기능이 용도에 따라 여러 부분으로 나뉠 수 있으며, 각 부분은 별도의 서버에 배치 → 여러 서버가 조합되어 하나의 사용자 요청 처리)
    - 서버 → RPC를 통해 통신 → RPC는 blocking
    - 따라서 RPC 호출을 비동기 호출로 수정해 cpu의 리소스가 낭비되게 하지 말자
    - non blocking → 함수 즉시 반환 → GetUserInfo() 를 호출해 함수 반환 시 사용자 응답에 대한 결과 추가
    - 하지만 코드가 복잡해짐 → 코루틴으로 비동기 프로그래밍 효율성 + 동기 프로그래밍의 단순성 으로 문제를 해결해 보자’

## 6. 코루틴

- 동기 방식의 비동기 프로그래밍
- handler → 동기 → 하지만 yield로 CPU 제어권을 반환(RPC 통신 시작 후 바로 호출)
- 코루틴이 일시 중지 되어도 작업자 스레드 블로킹 x → 다른 코루틴을 실행하기 위해 전환 → 일시 중지된 코루틴에 할당된 사용자 서비스가 응답한 후 그 처리 결과를 반환하면 다시 ready → 나중에 중지되었던 부분에서 이어서 다시 실행
- 코루틴이 RPC 요청으로 능동적으로 CPU 제어권 반환 → 작업자 스레드는 ready 상태인 다른 코루틴 실행 → 코루틴 블로킹, 작업자 스레드는 블로킹 x → 효율적!

## 7. cpu, 스레드, 코루틴

- cpu: 기계어 실행해서 컴퓨터를 움직이게 함
- 스레드: 커널로 생성되고 스케줄링 → 스레드 우선 순위에 따라 cpu 연산 리소스 할당
- 코루틴: 커널이 알 수 x → 커널은 코루틴 숫자와 상관없이 스레드에 따라 cpu 시간 할당

# 5. 컴퓨터 시스템 여행

## 1. 코드, 데이터, 변수, 포인터

- 메모리에 저장되는 데이터
    - 구조체 인스턴스, 객체, 배열 등
    - 별칭을 사용해 데이터를 지칭할 수 있고, 이를 통해 변수가 탄생
- pointer 변수를 통해 데이터 참조

## 2. 콜백 함수와 클로저

- 일급 객체 → 특정 언어에서 코드를 할당, 사용, 매개변수로 전달, 반환값으로 사용 등 일반 변수를 다루듯이 처리할 수 있는 것
- c → 함수가 일급 객체 x → 함수에서 다른 함수 반환 x
- 파이썬 → 함수가 일급 객체 → 일반 변수처럼 반환 o
- 콜백 함수 → 함수가 다른 함수에 매개변수로 전달
    - 콜백 함수는 정의와 호출을 다른 곳에서 함 → 이때 콜백 함수 정의부에서 얻을 수 있는 데이터를 콜백 함수가 호출되는 곳에서 사용할 수 있어야 함 → 이걸 묶어서 전달하는게 클로저

## 3. 컨테이너와 가상 머신 기술

- 코루틴: 어떤 함수가 cpu를 능동적으로 일시 중지하고 다음에 함수가 다시 호출될 때 앞에서 중단된 시점에 계속 실행하는 것이 가능한 함수
- 스레드: 함수의 일시 중지, 재개가 커널 상태에서 구현되는 경우
- 프로세스: 스레드에 주소 공간처럼 종속된 실행 시 리소스를 결합한 것
- 컨테이너: 프로그램이 의존하는 실행 환경과 함께 묶인 것 → 가상화 기술로 os 가상화 → 프로세스 격리 + cpu, memory, disk에 대한 접근 제어 → 컨테이너 안의 os는 자신의 process만 존재하고 있다 생각
- 하이퍼바이저: sw를 이용해 하드웨어 추상화 → hw 리소스를 가상 컴퓨터 여러 개로 나눔 → 이 위에서 os를 실행하면 os는 hw의 리소스를 가져와서 사용할 수 있게 해주는 역할
